[
  {
    "path": "posts/httprpubscomamerleaux864543/",
    "title": "HW2 Merleaux",
    "description": "Reading data in to R studio.",
    "author": [
      {
        "name": "April Merleaux",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\r\n\r\n\r\nknitr::opts_chunk$set(echo = TRUE)\r\nlibrary(readr)\r\nlibrary(tidyverse)\r\nlibrary(dplyr)\r\n\r\n\r\n\r\nFor HW 2 I analyzed poultry data, which were already tidy. I named the libraries in the setup chunk. Now I’m going to read in the csv and rename to a shorter name and view output and column names.\r\n\r\n\r\npoultry_tidy <- read_csv(\"C:/Users/am37/Documents/DATA/class work/poultry_tidy - poultry_tidy.csv\")\r\nview(poultry_tidy)\r\ncolnames(poultry_tidy)\r\n\r\n\r\n[1] \"Product\"      \"Year\"         \"Month\"        \"Price_Dollar\"\r\n\r\nDescribe the data\r\npoultry_tidy has four columns:\r\nProduct and Month are character vectors\r\nYear and Price_Dollar are doubles, or real numbers. The data includes the price in dollars by month and year for 5 different chicken cuts.\r\nDescribe the data wrangling\r\nI grouped by year and summarised to show the mean price in dollars for all types of chicken. omitted the NAs.\r\n\r\n\r\ngroup_by(poultry_tidy, Year) %>%\r\nsummarise(mean(Price_Dollar, na.rm = TRUE))\r\n\r\n\r\n# A tibble: 10 x 2\r\n    Year `mean(Price_Dollar, na.rm = TRUE)`\r\n   <dbl>                              <dbl>\r\n 1  2004                               3.25\r\n 2  2005                               3.36\r\n 3  2006                               3.36\r\n 4  2007                               3.36\r\n 5  2008                               3.40\r\n 6  2009                               3.42\r\n 7  2010                               3.39\r\n 8  2011                               3.36\r\n 9  2012                               3.49\r\n10  2013                               3.50\r\n\r\nNext, I groupby Year and Product and summarised by Price_Dollar to see how the price varies across Products within a single year\r\n\r\n\r\ngroup_by(poultry_tidy, Year, Product) %>%\r\nsummarise(mean(Price_Dollar, na.rm = TRUE))\r\n\r\n\r\n# A tibble: 50 x 3\r\n# Groups:   Year [10]\r\n    Year Product        `mean(Price_Dollar, na.rm = TRUE)`\r\n   <dbl> <chr>                                       <dbl>\r\n 1  2004 B/S Breast                                   6.43\r\n 2  2004 Bone-in Breast                               3.90\r\n 3  2004 Thighs                                       2.01\r\n 4  2004 Whole                                        2.12\r\n 5  2004 Whole Legs                                   1.99\r\n 6  2005 B/S Breast                                   6.45\r\n 7  2005 Bone-in Breast                               3.90\r\n 8  2005 Thighs                                       2.21\r\n 9  2005 Whole                                        2.17\r\n10  2005 Whole Legs                                   2.04\r\n# ... with 40 more rows\r\n\r\nI’m curious how Whole chicken prices change between 2004 and 2013. I grouped by Year, filtered for Whole, and summarised for the mean price. I omitted the NAs.\r\n\r\n\r\ngroup_by(poultry_tidy, Year) %>%\r\nfilter(Product == \"Whole\") %>%\r\nsummarise(mean(Price_Dollar, na.rm = TRUE))\r\n\r\n\r\n# A tibble: 10 x 2\r\n    Year `mean(Price_Dollar, na.rm = TRUE)`\r\n   <dbl>                              <dbl>\r\n 1  2004                               2.12\r\n 2  2005                               2.17\r\n 3  2006                               2.20\r\n 4  2007                               2.20\r\n 5  2008                               2.37\r\n 6  2009                               2.48\r\n 7  2010                               2.39\r\n 8  2011                               2.35\r\n 9  2012                               2.38\r\n10  2013                               2.38\r\n\r\nNow I wanted to know how price varies across months, so I’m going to group by month and summarise by mean price\r\n\r\n\r\ngroup_by(poultry_tidy, Month) %>%\r\nsummarise(mean(Price_Dollar, na.rm = TRUE))\r\n\r\n\r\n# A tibble: 12 x 2\r\n   Month     `mean(Price_Dollar, na.rm = TRUE)`\r\n   <chr>                                  <dbl>\r\n 1 April                                   3.38\r\n 2 August                                  3.40\r\n 3 December                                3.40\r\n 4 February                                3.38\r\n 5 January                                 3.39\r\n 6 July                                    3.40\r\n 7 June                                    3.39\r\n 8 March                                   3.38\r\n 9 May                                     3.38\r\n10 November                                3.40\r\n11 October                                 3.40\r\n12 September                               3.40\r\n\r\nI wonder which cut of chicken is cheapest?\r\n\r\n\r\ngroup_by(poultry_tidy, Product) %>%\r\n  summarise(mean(Price_Dollar, na.rm = TRUE))\r\n\r\n\r\n# A tibble: 5 x 2\r\n  Product        `mean(Price_Dollar, na.rm = TRUE)`\r\n  <chr>                                       <dbl>\r\n1 B/S Breast                                   6.55\r\n2 Bone-in Breast                               3.90\r\n3 Thighs                                       2.18\r\n4 Whole                                        2.31\r\n5 Whole Legs                                   2.03\r\n\r\nIt looks like Whole Legs are the cheapest. That’s not surprising. I am a little surprised at how much cheaper they are than the most expensive cut.\r\n\r\n\r\n#groupby month, filter to just look at Whole Legs, and pivot wider to look at the months against the years\r\ngroup_by(poultry_tidy, Month) %>%\r\nfilter(Product == \"Whole Legs\") %>%\r\npivot_wider(names_from = Year, values_from = Price_Dollar)\r\n\r\n\r\n# A tibble: 12 x 12\r\n# Groups:   Month [12]\r\n   Product    Month   `2013` `2012` `2011` `2010` `2009` `2008` `2007`\r\n   <chr>      <chr>    <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\r\n 1 Whole Legs January   2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n 2 Whole Legs Februa~   2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n 3 Whole Legs March     2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n 4 Whole Legs April     2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n 5 Whole Legs May       2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n 6 Whole Legs June      2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n 7 Whole Legs July      2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n 8 Whole Legs August    2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n 9 Whole Legs Septem~   2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n10 Whole Legs October   2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n11 Whole Legs Novemb~   2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n12 Whole Legs Decemb~   2.04   2.04   2.04   2.04   2.04   2.04   2.04\r\n# ... with 3 more variables: 2006 <dbl>, 2005 <dbl>, 2004 <dbl>\r\n\r\nIt is very strange to me that there is so little variation in the price of Whole Legs. It makes me wonder if there’s something funky with the data.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-13T15:57:08-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httprpubscomanneetienne864237/",
    "title": "HW1",
    "description": "This is the first homework but im so late i am catching up sorry",
    "author": [
      {
        "name": "Anne Etienne",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-13T15:56:55-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httprpubscomericalaidler864561/",
    "title": "HW 1 601",
    "description": "RPub submission",
    "author": [
      {
        "name": "Erica Laidler",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-13T15:57:12-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomahungundaphhw2/",
    "title": "HW2",
    "description": "DACSS 601 Data Science Fundamentals - Homework 2",
    "author": [
      {
        "name": "Apoorva Hungund",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\nR Markdown HW2\n#For this assignment, I’m exploring the Airbnb data in NY dataset, specifically looking at Airbnb rates in Manhattan and Brooklyn.\n\n\n##1) Read in a dataset & view it.\nbookings<-read.csv2(file = \"AB_NYC_2019.csv\", sep = \",\")\ndim(bookings)\n\n\n[1] 48895    16\n\nhead(bookings)\n\n\n    id                                             name host_id\n1 2539               Clean & quiet apt home by the park    2787\n2 2595                            Skylit Midtown Castle    2845\n3 3647              THE VILLAGE OF HARLEM....NEW YORK !    4632\n4 3831                  Cozy Entire Floor of Brownstone    4869\n5 5022 Entire Apt: Spacious Studio/Loft by central park    7192\n6 5099        Large Cozy 1 BR Apartment In Midtown East    7322\n    host_name neighbourhood_group neighbourhood latitude longitude\n1        John            Brooklyn    Kensington 40.64749 -73.97237\n2    Jennifer           Manhattan       Midtown 40.75362 -73.98377\n3   Elisabeth           Manhattan        Harlem 40.80902  -73.9419\n4 LisaRoxanne            Brooklyn  Clinton Hill 40.68514 -73.95976\n5       Laura           Manhattan   East Harlem 40.79851 -73.94399\n6       Chris           Manhattan   Murray Hill 40.74767   -73.975\n        room_type price minimum_nights number_of_reviews last_review\n1    Private room   149              1                 9  2018-10-19\n2 Entire home/apt   225              1                45  2019-05-21\n3    Private room   150              3                 0            \n4 Entire home/apt    89              1               270  2019-07-05\n5 Entire home/apt    80             10                 9  2018-11-19\n6 Entire home/apt   200              3                74  2019-06-22\n  reviews_per_month calculated_host_listings_count availability_365\n1              0.21                              6              365\n2              0.38                              2              355\n3                                                1              365\n4              4.64                              1              194\n5              0.10                              1                0\n6              0.59                              1              129\n\n\n\n##2) Explain variables in dataset.\nlapply(bookings,class)\n\n\n$id\n[1] \"integer\"\n\n$name\n[1] \"character\"\n\n$host_id\n[1] \"integer\"\n\n$host_name\n[1] \"character\"\n\n$neighbourhood_group\n[1] \"character\"\n\n$neighbourhood\n[1] \"character\"\n\n$latitude\n[1] \"character\"\n\n$longitude\n[1] \"character\"\n\n$room_type\n[1] \"character\"\n\n$price\n[1] \"integer\"\n\n$minimum_nights\n[1] \"integer\"\n\n$number_of_reviews\n[1] \"integer\"\n\n$last_review\n[1] \"character\"\n\n$reviews_per_month\n[1] \"character\"\n\n$calculated_host_listings_count\n[1] \"integer\"\n\n$availability_365\n[1] \"integer\"\n\nsummary(bookings)\n\n\n       id               name              host_id         \n Min.   :    2539   Length:48895       Min.   :     2438  \n 1st Qu.: 9471945   Class :character   1st Qu.:  7822033  \n Median :19677284   Mode  :character   Median : 30793816  \n Mean   :19017143                      Mean   : 67620011  \n 3rd Qu.:29152178                      3rd Qu.:107434423  \n Max.   :36487245                      Max.   :274321313  \n  host_name         neighbourhood_group neighbourhood     \n Length:48895       Length:48895        Length:48895      \n Class :character   Class :character    Class :character  \n Mode  :character   Mode  :character    Mode  :character  \n                                                          \n                                                          \n                                                          \n   latitude          longitude          room_type        \n Length:48895       Length:48895       Length:48895      \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n     price         minimum_nights    number_of_reviews\n Min.   :    0.0   Min.   :   1.00   Min.   :  0.00   \n 1st Qu.:   69.0   1st Qu.:   1.00   1st Qu.:  1.00   \n Median :  106.0   Median :   3.00   Median :  5.00   \n Mean   :  152.7   Mean   :   7.03   Mean   : 23.27   \n 3rd Qu.:  175.0   3rd Qu.:   5.00   3rd Qu.: 24.00   \n Max.   :10000.0   Max.   :1250.00   Max.   :629.00   \n last_review        reviews_per_month  calculated_host_listings_count\n Length:48895       Length:48895       Min.   :  1.000               \n Class :character   Class :character   1st Qu.:  1.000               \n Mode  :character   Mode  :character   Median :  1.000               \n                                       Mean   :  7.144               \n                                       3rd Qu.:  2.000               \n                                       Max.   :327.000               \n availability_365\n Min.   :  0.0   \n 1st Qu.:  0.0   \n Median : 45.0   \n Mean   :112.8   \n 3rd Qu.:227.0   \n Max.   :365.0   \n\n\nThis dataset described the data for Airbnb prices in different boroughts of NYC. Along with necessary \ndescriptive variables such as name, host id, host name, neighborhood_group, neighborhood, latitude, \nlongitude, room_type, minimum_nights, reviews-related variables, etc. \nthere are also variables that may affect the rating of the listings.\n\nVariables are either character variables - such as name, host_name, neighborhood, etc., or \ninteger variables - such as price, reviews for, etc. There are 48895 entries and 16 columns.\n\n\n\ncolSums(is.na(bookings))\n\n\n                            id                           name \n                             0                              0 \n                       host_id                      host_name \n                             0                              0 \n           neighbourhood_group                  neighbourhood \n                             0                              0 \n                      latitude                      longitude \n                             0                              0 \n                     room_type                          price \n                             0                              0 \n                minimum_nights              number_of_reviews \n                             0                              0 \n                   last_review              reviews_per_month \n                             0                              0 \ncalculated_host_listings_count               availability_365 \n                             0                              0 \n\n##From this, we can see that there no NAs.\n\n\n\n\n\n##3)\n##Select columns\ndata_bookings <- dplyr::select(bookings, name, neighbourhood_group, neighbourhood, room_type, price, number_of_reviews)\nhead(data_bookings)\n\n\n                                              name\n1               Clean & quiet apt home by the park\n2                            Skylit Midtown Castle\n3              THE VILLAGE OF HARLEM....NEW YORK !\n4                  Cozy Entire Floor of Brownstone\n5 Entire Apt: Spacious Studio/Loft by central park\n6        Large Cozy 1 BR Apartment In Midtown East\n  neighbourhood_group neighbourhood       room_type price\n1            Brooklyn    Kensington    Private room   149\n2           Manhattan       Midtown Entire home/apt   225\n3           Manhattan        Harlem    Private room   150\n4            Brooklyn  Clinton Hill Entire home/apt    89\n5           Manhattan   East Harlem Entire home/apt    80\n6           Manhattan   Murray Hill Entire home/apt   200\n  number_of_reviews\n1                 9\n2                45\n3                 0\n4               270\n5                 9\n6                74\n\n##Filter data based on Manhattan and Brooklyn & arrange by highest price\n\nbookings_brooklyn<-data_bookings %>%\n  dplyr::filter(neighbourhood_group == \"Brooklyn\") %>%\n  arrange(desc(price))\nrmarkdown::paged_table(head(bookings_brooklyn))\n\n\n\n\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"neighbourhood_group\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"neighbourhood\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"room_type\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"price\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"number_of_reviews\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Luxury 1 bedroom apt. -stunning Manhattan views\",\"2\":\"Brooklyn\",\"3\":\"Greenpoint\",\"4\":\"Entire home/apt\",\"5\":\"10000\",\"6\":\"5\",\"_rn_\":\"1\"},{\"1\":\"Film Location\",\"2\":\"Brooklyn\",\"3\":\"Clinton Hill\",\"4\":\"Entire home/apt\",\"5\":\"8000\",\"6\":\"1\",\"_rn_\":\"2\"},{\"1\":\"Gem of east Flatbush\",\"2\":\"Brooklyn\",\"3\":\"East Flatbush\",\"4\":\"Private room\",\"5\":\"7500\",\"6\":\"8\",\"_rn_\":\"3\"},{\"1\":\"SUPER BOWL Brooklyn Duplex Apt!!\",\"2\":\"Brooklyn\",\"3\":\"Clinton Hill\",\"4\":\"Entire home/apt\",\"5\":\"6500\",\"6\":\"0\",\"_rn_\":\"4\"},{\"1\":\"NearWilliamsburg bridge 11211 BK\",\"2\":\"Brooklyn\",\"3\":\"Bedford-Stuyvesant\",\"4\":\"Private room\",\"5\":\"5000\",\"6\":\"10\",\"_rn_\":\"5\"},{\"1\":\"Fulton 2\",\"2\":\"Brooklyn\",\"3\":\"Cypress Hills\",\"4\":\"Entire home/apt\",\"5\":\"5000\",\"6\":\"4\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nbookings_manhattan<-data_bookings %>%\n  dplyr::filter(neighbourhood_group == \"Manhattan\") %>%\n  arrange(desc(price))\nrmarkdown::paged_table(head(bookings_manhattan))\n\n\n\n\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"neighbourhood_group\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"neighbourhood\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"room_type\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"price\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"number_of_reviews\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1-BR Lincoln Center\",\"2\":\"Manhattan\",\"3\":\"Upper West Side\",\"4\":\"Entire home/apt\",\"5\":\"10000\",\"6\":\"0\",\"_rn_\":\"1\"},{\"1\":\"Spanish Harlem Apt\",\"2\":\"Manhattan\",\"3\":\"East Harlem\",\"4\":\"Entire home/apt\",\"5\":\"9999\",\"6\":\"1\",\"_rn_\":\"2\"},{\"1\":\"Quiet, Clean, Lit @ LES & Chinatown\",\"2\":\"Manhattan\",\"3\":\"Lower East Side\",\"4\":\"Private room\",\"5\":\"9999\",\"6\":\"6\",\"_rn_\":\"3\"},{\"1\":\"2br - The Heart of NYC: Manhattans Lower East Side\",\"2\":\"Manhattan\",\"3\":\"Lower East Side\",\"4\":\"Entire home/apt\",\"5\":\"9999\",\"6\":\"0\",\"_rn_\":\"4\"},{\"1\":\"Beautiful/Spacious 1 bed luxury flat-TriBeCa/Soho\",\"2\":\"Manhattan\",\"3\":\"Tribeca\",\"4\":\"Entire home/apt\",\"5\":\"8500\",\"6\":\"2\",\"_rn_\":\"5\"},{\"1\":\"East 72nd Townhouse by (Hidden by Airbnb)\",\"2\":\"Manhattan\",\"3\":\"Upper East Side\",\"4\":\"Entire home/apt\",\"5\":\"7703\",\"6\":\"0\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-13T15:56:52-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscombkruzlichw1attempt4/",
    "title": "Bryn Kruzlic HW1",
    "description": "This is the first homework for DACSS601",
    "author": [
      {
        "name": "Bryn Kruzlic",
        "url": "https://rpubs.com/bkruzlic"
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-13T15:57:23-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscombkruzlichw2attempt1/",
    "title": "Kruzlic HW2 Try 1",
    "description": "DACSS 601 Homework 2 Example",
    "author": [
      {
        "name": "Bryn Kruzlic",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\r\nFunctions: These are the libraries needed for the dataset\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(readr)\r\n\r\n\r\n\r\nVariables: These are the variables in the dataset railroad\r\n\r\nstate: state represents the 53 states in America\r\ntotal_employees: total_employees represents the number of employees in each state\r\n\r\nThis is how to read in a dataset using read_csv\r\n\r\nA ‘tibble’ refers to a data frame\r\n\r\n\r\n\r\nlibrary(readr)\r\nData <- read_csv(\"C:/Users/Bryn Kruzlic/OneDrive/Desktop/DACSS601/railroad_2012_clean_state.csv\")\r\ncol_names = c(chr = \"x\", dbl = \"y\")\r\nView(Data)\r\nas_tibble(Data) # A tibble: 10 x 2\r\n\r\n\r\n# A tibble: 53 x 2\r\n   state total_employees\r\n   <chr>           <dbl>\r\n 1 AE                  2\r\n 2 AK                103\r\n 3 AL               4257\r\n 4 AP                  1\r\n 5 AR               3871\r\n 6 AZ               3153\r\n 7 CA              13137\r\n 8 CO               3650\r\n 9 CT               2592\r\n10 DC                279\r\n# ... with 43 more rows\r\n\r\nsummary(Data)\r\n\r\n\r\n    state           total_employees\r\n Length:53          Min.   :    1  \r\n Class :character   1st Qu.: 1917  \r\n Mode  :character   Median : 3379  \r\n                    Mean   : 4819  \r\n                    3rd Qu.: 6092  \r\n                    Max.   :19839  \r\n\r\nPerform at least 2 basic data-wrangling operations\r\n\r\n\r\nlibrary(dplyr)\r\nfilter(Data, total_employees > 1000) %>%\r\n  arrange(desc(total_employees))\r\n\r\n\r\n# A tibble: 42 x 2\r\n   state total_employees\r\n   <chr>           <dbl>\r\n 1 TX              19839\r\n 2 IL              19131\r\n 3 NY              17050\r\n 4 NE              13176\r\n 5 CA              13137\r\n 6 PA              12769\r\n 7 OH               9056\r\n 8 GA               8605\r\n 9 IN               8537\r\n10 MO               8419\r\n# ... with 32 more rows\r\n\r\n\r\nWe are using functions filter() and arrange () to filter out the states with more than 1000 total employees and then arranging them in descending order.\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-13T15:57:27-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomhenryfnp865058/",
    "title": "Henry Nguyen HW2",
    "description": "This is Henry's homework number 2.",
    "author": [
      {
        "name": "Henry Nguyen",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\nHomework #2\nThis is an R Markdown document to complete the tasks assigned in homework #2. It will read in a dataset. The variables will be explained. Simple data-wrangling operations will be demonstrated.\nPoultry Data Description\nThis data shows the price in dollars by poultry product type, month, and year. Each column is a variable and each row is an observation.\nThis data set has four variables:\nProduct\nthis variable is character data\nthis variable is the type of poultry products per observation\n\nYear\nthis variable is character data\nthis variable is the year of each observation\n\nMonth\nthis variable is character data\nthis variable is month of each observation\n\nPrice_Dollar\nthis variable is real number data\nthis variable is the price of each observation\n\nData Wrangling\n\n\nlibrary(tidyverse)\npoultry <- read_csv(\"poultry_tidy - poultry_tidy.csv\")\n\npoultry%>%\n  select(Product, Year, Price_Dollar)%>%\n  arrange(desc(Price_Dollar))\n\n\n# A tibble: 600 × 3\n   Product     Year Price_Dollar\n   <chr>      <dbl>        <dbl>\n 1 B/S Breast  2013         7.04\n 2 B/S Breast  2013         7.04\n 3 B/S Breast  2013         7.04\n 4 B/S Breast  2013         7.04\n 5 B/S Breast  2013         7.04\n 6 B/S Breast  2013         7.04\n 7 B/S Breast  2013         7.04\n 8 B/S Breast  2013         7.04\n 9 B/S Breast  2013         7.04\n10 B/S Breast  2013         7.04\n# … with 590 more rows\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-13T15:57:16-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomikennedy040hw2/",
    "title": "HW2_IanKennedy",
    "description": "HW2 for DACSS 601. There are four columns of data in the selected spreadsheet. Territory (string), resp (string), count (numerical), and percent (numerical). I also created a new column labeled 'High Count' (string) and used the 'select' tool to show only the following columns: territory, count, & High_Count",
    "author": [
      {
        "name": "Ian Kennedy",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\r\n\r\n\r\nHW2_Data <- read_excel(path = \"C:/Users/kenne/Documents/R_Workspace/australian_marriage_tidy.xlsx\")\r\nHW2_Data %>%\r\n  arrange(desc(count))%>%\r\n  mutate(High_Count = case_when(count >= 2000000 ~ \"High\",\r\n                                count < 2000000 ~ \"Low\" ))%>%\r\n  select(territory, count, High_Count)\r\n\r\n\r\n# A tibble: 16 x 3\r\n   territory                         count High_Count\r\n   <chr>                             <dbl> <chr>     \r\n 1 New South Wales                 2374362 High      \r\n 2 Victoria                        2145629 High      \r\n 3 New South Wales                 1736838 Low       \r\n 4 Queensland                      1487060 Low       \r\n 5 Victoria                        1161098 Low       \r\n 6 Queensland                       961015 Low       \r\n 7 Western Australia                801575 Low       \r\n 8 South Australia                  592528 Low       \r\n 9 Western Australia                455924 Low       \r\n10 South Australia                  356247 Low       \r\n11 Tasmania                         191948 Low       \r\n12 Australian Capital Territory(c)  175459 Low       \r\n13 Tasmania                         109655 Low       \r\n14 Australian Capital Territory(c)   61520 Low       \r\n15 Northern Territory(b)             48686 Low       \r\n16 Northern Territory(b)             31690 Low       \r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-13T15:56:25-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomikennedy040hw3/",
    "title": "HW3_IanKennedy",
    "description": "HW3 for DACSS 601.",
    "author": [
      {
        "name": "Ian Kennedy",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\r\nFor my final project I’ll be using a data set from the Research Lab (FFRC) I’ve been working with for the past few years. In short, the FFRC, in coordination with the USDA Forest Service, implements an annual survey (TPO) which attempts to track timber procurement and lumber production at mills throughout the USA. Below, I’ve selected the columns of interest, of which there are 5. MILL_NBR (numeric), MILL_STATECD (numeric), MILL_NAME (string), and MILL_STATUS_CD (numeric) are all included for identification purposes. TOT_MCF (numeric) is the column of interest, as I’ll be looking to gauge the breadth of mills included in our survey efforts. Specifically, I’ll be running analyses to see how shifting the baseline for minimum volume procured (TOT_MCF) would impact the number of mills and total volume of procured timber included in the sample frame. I’ve also added a new column (Volume_Code) which will be updated based on the volume that is landed on. Generally speaking, this sort of analysis will attempt to answer the following research questions:\r\nDoes it make sense to exclude small-production/hobby mills from future survey attempts?\r\nIf yes, what is the minimum volume (TOT_MCF) that mills should have procured to be included in survey efforts?\r\nWhat impact would shifting the baseline (regardless of minimum volume utilized) have on the total volume and number of mills that are surveyed?\r\nThere will likely be further questions that will need to be analyzed, however these questions outline the main priorities of data analysis for this project.\r\n\r\n\r\nHW3_Data <- read_excel(path = \"C:/Users/kenne/Documents/R_Workspace/TPO_Sample.xlsx\")\r\nHW3_Data %>%\r\n  select(MILL_NBR, MILL_STATECD, MILL_NAME, MILL_STATUS_CD, TOT_MCF)%>%\r\n  arrange(TOT_MCF)%>%\r\n  mutate(Volume_Code = case_when(TOT_MCF > 1.6666667 ~ 2, \r\n                                 TOT_MCF <= 1.6666667 ~ 1))%>%\r\n  arrange(Volume_Code)%>%\r\n\r\n  head()\r\n\r\n\r\n# A tibble: 6 x 6\r\n  MILL_NBR   MILL_STATECD MILL_NAME MILL_STATUS_CD TOT_MCF Volume_Code\r\n  <chr>             <dbl> <chr>              <dbl>   <dbl>       <dbl>\r\n1 3005                 55 NEWPAGE ~             NA 0                 1\r\n2 5                    34 ON-SITE ~              2 0.00953           1\r\n3 902                  26 FARMER B~              2 0.0172            1\r\n4 344                  27 PRAIRIE ~              2 0.02              1\r\n5 N/A - Nev~           18 ROGER BR~              3 0.0316            1\r\n6 731                  26 PINE RID~              2 0.0316            1\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-13T15:56:32-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscommeade68863819/",
    "title": "Homework 2, Data Import",
    "description": "Second Assignment",
    "author": [
      {
        "name": "Justin Meade",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\r\nI am using StateCounty2012.xls from the example datasets\r\n1. Read dataset\r\nLoad Tidyverse and readxl to import .xls, Set working directory to location with R script, import dataset\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(readxl)\r\nsetwd('G:/My Drive/School/UMASS/DACSS/DACSS_601/assignment2')\r\nexampleCounties <- filter(select(read_xls('./StateCounty2012.xls',skip=3),STATE,COUNTY,TOTAL), !is.na(COUNTY))\r\n\r\n\r\n\r\nDisplay First 10 Records of exampleCounties\r\n\r\n\r\nhead(exampleCounties,n=10L)\r\n\r\n\r\n# A tibble: 10 x 3\r\n   STATE COUNTY               TOTAL\r\n   <chr> <chr>                <dbl>\r\n 1 AE    APO                      2\r\n 2 AK    ANCHORAGE                7\r\n 3 AK    FAIRBANKS NORTH STAR     2\r\n 4 AK    JUNEAU                   3\r\n 5 AK    MATANUSKA-SUSITNA        2\r\n 6 AK    SITKA                    1\r\n 7 AK    SKAGWAY MUNICIPALITY    88\r\n 8 AL    AUTAUGA                102\r\n 9 AL    BALDWIN                143\r\n10 AL    BARBOUR                  1\r\n\r\n2. Explain the variables in the exampleCounties:\r\n\r\n\r\nstr(exampleCounties)\r\n\r\n\r\ntibble [2,930 x 3] (S3: tbl_df/tbl/data.frame)\r\n $ STATE : chr [1:2930] \"AE\" \"AK\" \"AK\" \"AK\" ...\r\n $ COUNTY: chr [1:2930] \"APO\" \"ANCHORAGE\" \"FAIRBANKS NORTH STAR\" \"JUNEAU\" ...\r\n $ TOTAL : num [1:2930] 2 7 2 3 2 1 88 102 143 1 ...\r\n\r\n‘STATE’ column contains state names, character column type. ‘CTY’ column contains county names, character column type. ‘TOTAL’ column is numeric; it denotes a total.\r\n3. Data Wrangling Operations!!\r\n1st Data-Wrangling operation\r\nCreate datafreme, exampleCounties2. Contains only records where STATE starts with ‘MA’ arranged by descending TOTAL\r\n\r\n\r\nexampleCounties2 <- arrange(filter(exampleCounties, startsWith(STATE, 'MA')), 0-TOTAL)\r\nhead(exampleCounties2, n=20L)\r\n\r\n\r\n# A tibble: 12 x 3\r\n   STATE COUNTY     TOTAL\r\n   <chr> <chr>      <dbl>\r\n 1 MA    MIDDLESEX    673\r\n 2 MA    SUFFOLK      558\r\n 3 MA    PLYMOUTH     429\r\n 4 MA    NORFOLK      386\r\n 5 MA    ESSEX        314\r\n 6 MA    WORCESTER    310\r\n 7 MA    BRISTOL      232\r\n 8 MA    HAMPDEN      202\r\n 9 MA    FRANKLIN     113\r\n10 MA    HAMPSHIRE     68\r\n11 MA    BERKSHIRE     50\r\n12 MA    BARNSTABLE    44\r\n\r\nSTATE == ‘TX’ AND TOTAL >= 300, arranged alphabetically.\r\n\r\n\r\nhead(arrange(exampleCounties %>%\r\n  filter(STATE =='TX') %>% filter(TOTAL >= 300),COUNTY))\r\n\r\n\r\n# A tibble: 6 x 3\r\n  STATE COUNTY  TOTAL\r\n  <chr> <chr>   <dbl>\r\n1 TX    BELL      413\r\n2 TX    BEXAR     950\r\n3 TX    DALLAS    406\r\n4 TX    DENTON    394\r\n5 TX    EL PASO   863\r\n6 TX    HARRIS   2535\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-13T15:56:39-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomrmelendez864255/",
    "title": "Homework 1",
    "description": "R Pub Test",
    "author": [
      {
        "name": "Roberto Melendez",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\nR Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\n\nsummary(cars)\n\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\nIncluding Plots\nYou can also embed plots, for example:\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot.\n\n\n\n",
    "preview": "posts/httpsrpubscomrmelendez864255/distill-preview.png",
    "last_modified": "2022-02-13T15:56:59-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomtcwilso3hw3wilson/",
    "title": "Homework3_Wilson",
    "description": "HW3 - Data Wrangling",
    "author": [
      {
        "name": "Thomas Wilson",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\nThis dataset contains raw and corrected rates of primate behavioural innovation, tool use, extractive foraging, social learning and research effort\nCitation: The evolution of primate general and cultural intelligence. Reader SM, Hager Y & Laland KN. Philosophical Transactions of the Royal Society B, 2011 366:1017-1027\nVariables include: Species name, Taxon, Great Ape (y/n?), Times of recorded observations of: Innovation, Tool use, Extractive foraging, and Social learning.\n\n\nData_ReaderHagerLalandPhilTrans2011 <- read_csv(\"Data_ReaderHagerLalandPhilTrans2011.csv\")\nView(Data_ReaderHagerLalandPhilTrans2011)\nPrimate_ToolUse <- Data_ReaderHagerLalandPhilTrans2011\nview(Primate_ToolUse)\ndim(Primate_ToolUse)\n\n\n[1] 238  20\n\n#Removed columns that weren't useful to potential research questions\nPrimate_ToolUse <- Primate_ToolUse[-c(2:4,11:20)]\nview(Primate_ToolUse)\n\n#Filter out any entry that has zero observations of innovation\nPrimate_ToolUse %>%\n  filter(Innovation > 0) \n\n\n# A tibble: 49 x 7\n   Species    Taxon `Great ape` Innovation `Tool use` `Extractive for…\n   <chr>      <chr> <chr>            <dbl>      <dbl>            <dbl>\n 1 Callimico… Simi… No                   1          0                1\n 2 Callithri… Simi… No                   1          0                2\n 3 Callithri… Simi… No                   1          0                0\n 4 Cebus ape… Simi… No                  39         64               56\n 5 Cebus cap… Simi… No                   4          7                3\n 6 Cebus oli… Simi… No                   4          3                2\n 7 Daubenton… Pros… No                   4          2                6\n 8 Gorilla g… Simi… Great ape           25         21               12\n 9 Macaca ar… Simi… No                   1          1                1\n10 Macaca fa… Simi… No                   7          3                2\n# … with 39 more rows, and 1 more variable: Social learning <dbl>\n\n#Graphing:\nPrimate_ToolUse %>%\n  filter(grepl('Papio', Species)) %>%\n  ggplot(aes(x=Species, y=Innovation)) +\n  geom_point() +\n  labs(title = \"Number of Observed Innovation by Papio Species\", y = \"Number of Observations\", x = \"Species Name\") +\n  theme_classic()\n\n\n\nPrimate_ToolUse %>%\n  filter(grepl('Macaca', Species)) %>%\n  ggplot(aes(x=Species, y=`Social learning`)) +\n  geom_point() +\n  labs(title = \"Number of Observed Social Learning by Macaca Species\", y = \"Number of Observations\", x = \"Species Name\") +\n  theme_bw()\n\n\n\nPrimate_ToolUse %>%\n  filter(grepl('Great', `Great ape`)) %>%\n  ggplot(aes(x=Species, y=`Tool use`)) +\n  geom_point() +\n  labs(title = \"Number of Times Tool Use Observed in Great Apes\", y = \"Number of Observations\", x = \"Species Name\") +\n  theme_classic()\n\n\n\n\nPotential Research Questions:\nIs social learning of tool use an early example of culture? If so, when do we first see social learning present in humans/our human ancestors?\nWhy is tool use more common in the Macaca genus than any other Asian and African monkeys?\n\n\n\n",
    "preview": "posts/httpsrpubscomtcwilso3hw3wilson/distill-preview.png",
    "last_modified": "2022-02-13T15:57:04-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomtlamkin860400/",
    "title": "HW1",
    "description": "General Markdown File for Distill",
    "author": [
      {
        "name": "TLamkin",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\r\nINTRODUCTION\r\nTrying to get a project to publish on RPub and then, hopefully, my GitHub repository\r\nAddition\r\nAddition, for example:\r\n\r\n\r\n1+1\r\n\r\n\r\n[1] 2\r\n\r\nSubraction\r\nSubraction, for example:\r\n\r\n\r\n5-4\r\n\r\n\r\n[1] 1\r\n\r\n9-2\r\n\r\n\r\n[1] 7\r\n\r\n\r\nRadius\r\nRadius of a circle, for example:\r\n\r\n\r\nx <- 5  # radius of a circle\r\nx**2 * pi\r\n\r\n\r\n[1] 78.53982\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/httpsrpubscomtlamkin860400/distill-preview.png",
    "last_modified": "2022-02-13T15:56:47-05:00",
    "input_file": {},
    "preview_width": 1148,
    "preview_height": 375
  },
  {
    "path": "posts/httpsrpubscomtlamkin862725/",
    "title": "HW2",
    "description": "reading in 2 clean data sets and one untidy dataset",
    "author": [
      {
        "name": "TLamkin",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\r\nINTRODUCTION\r\nThis is an example of reading in 3 files of data:\r\nClean CSV\r\nClean Excel\r\nUncleaned Excel\r\nLoad Necessary Packages & Libraries and Load Clean CSV & Excel\r\nThe first step is verifying that working directory and library directory are set to the same path.\r\nThe next step is to install the necessary packages and load the necessary libraries.\r\nThen load in the railroad datasets.\r\nThere are 2 bits of data manipuation performed on the data.\r\n- ARRANGE()\r\n- FILTER()\r\nTo confirm: The data in both railroad files is:\r\nColumn 1 - character\r\nColumn 2 - Double class (dbl - double percision float)\r\n\r\n\r\n# Verify library path\r\n\r\n.libPaths()\r\n\r\n\r\n[1] \"C:/Users/theresa/Documents/R/win-library/4.1\"\r\n[2] \"C:/Program Files/R/R-4.1.2/library\"          \r\n\r\n# set the working directory to be the same as the library path\r\n\r\nsetwd(\"C:/Users/theresa/Documents/R/win-library/4.1\")\r\n\r\n# verify the working directory\r\n\r\ngetwd()\r\n\r\n\r\n[1] \"C:/Users/theresa/Documents/R/win-library/4.1\"\r\n\r\n# Installing Tidyverse and readxl packages with explicitly defining the URL of where it lives. This is to get around a Mirror error. \r\n\r\ninstall.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\r\n\r\n\r\npackage 'tidyverse' successfully unpacked and MD5 sums checked\r\n\r\nThe downloaded binary packages are in\r\n    C:\\Users\\theresa\\AppData\\Local\\Temp\\Rtmpwp0pBK\\downloaded_packages\r\n\r\ninstall.packages(\"readxl\", repos = \"http://cran.us.r-project.org\")\r\n\r\n\r\npackage 'readxl' successfully unpacked and MD5 sums checked\r\n\r\nThe downloaded binary packages are in\r\n    C:\\Users\\theresa\\AppData\\Local\\Temp\\Rtmpwp0pBK\\downloaded_packages\r\n\r\n# load the necessary libraries for the processing\r\n\r\nlibrary(tidyverse)\r\nlibrary(dbplyr)\r\nlibrary(readxl)\r\nlibrary(readr)\r\n\r\n# Load in the files and display them for clarification. \r\n\r\nrailroad_csv <- read_csv(\"c:/users/theresa/Documents/DACSS Local/DataSets/railroad_2012_clean_state.csv\", show_col_types = TRUE, skip=0)\r\nrailroad_exl <- read_excel(\"c:/users/theresa/Documents/DACSS Local/DataSets/railroad_2012_clean_state.xlsx\", skip = 0)\r\nrailroad_csv\r\n\r\n\r\n# A tibble: 53 x 2\r\n   state total_employees\r\n   <chr>           <dbl>\r\n 1 AE                  2\r\n 2 AK                103\r\n 3 AL               4257\r\n 4 AP                  1\r\n 5 AR               3871\r\n 6 AZ               3153\r\n 7 CA              13137\r\n 8 CO               3650\r\n 9 CT               2592\r\n10 DC                279\r\n# ... with 43 more rows\r\n\r\nrailroad_exl\r\n\r\n\r\n# A tibble: 53 x 2\r\n   state total_employees\r\n   <chr>           <dbl>\r\n 1 AE                  2\r\n 2 AK                103\r\n 3 AL               4257\r\n 4 AP                  1\r\n 5 AR               3871\r\n 6 AZ               3153\r\n 7 CA              13137\r\n 8 CO               3650\r\n 9 CT               2592\r\n10 DC                279\r\n# ... with 43 more rows\r\n\r\n# Arrange the resulting CSV by number of employees - Demonstration of the use of ARRANGE()\r\n\r\nby_num_employee <- railroad_csv %>% arrange(desc(total_employees))\r\n\r\n# Display the new order \r\n\r\nby_num_employee\r\n\r\n\r\n# A tibble: 53 x 2\r\n   state total_employees\r\n   <chr>           <dbl>\r\n 1 TX              19839\r\n 2 IL              19131\r\n 3 NY              17050\r\n 4 NE              13176\r\n 5 CA              13137\r\n 6 PA              12769\r\n 7 OH               9056\r\n 8 GA               8605\r\n 9 IN               8537\r\n10 MO               8419\r\n# ... with 43 more rows\r\n\r\n# See only MA data - Demonstrate the use of of FILTER()\r\n\r\nMassachusetts <- railroad_csv %>% filter(state == 'MA')\r\n\r\nMassachusetts\r\n\r\n\r\n# A tibble: 1 x 2\r\n  state total_employees\r\n  <chr>           <dbl>\r\n1 MA               3379\r\n\r\n# multi dplyr functions in 1 statement\r\n\r\nhighest_employee_count <- railroad_csv %>% \r\n    filter(total_employees > 10000) %>%\r\n    arrange(state)\r\n\r\nhighest_employee_count\r\n\r\n\r\n# A tibble: 6 x 2\r\n  state total_employees\r\n  <chr>           <dbl>\r\n1 CA              13137\r\n2 IL              19131\r\n3 NE              13176\r\n4 NY              17050\r\n5 PA              12769\r\n6 TX              19839\r\n\r\nLoad Unclean Excel Approach 1 - Load All Sheets - Data not cleaned After Loading\r\nThis is loading in the Australian Marriage Data file with multiple tabs. I did this with a user defined function and lapply. The data in these files is all loaded as characters. This loaded all 4 sheets. Not ideal because the first and last sheets do not contain data.\r\n\r\n\r\n# create a function that will take in the file and load the separate sheets into tibbles.  \r\n\r\nmultiplesheets <- function(fname) {\r\n   \r\n# getting info about all excel sheet tab names\r\n  \r\n  sheet_names <- readxl::excel_sheets(fname)\r\n  \r\n# display the tab names for easy understanding\r\n  \r\n  print(sheet_names)\r\n  \r\n# load the data from each sheet into its own data set using lapply. \r\n\r\n  data_sheets <- lapply(sheet_names, function(x) \r\n          { \r\n          readxl::read_excel(fname, sheet = x)\r\n          }\r\n          )\r\n \r\n list_data <- lapply(data_sheets, as.data.frame)\r\n\r\n# display the data in all the generated data sheets\r\n  \r\n  print(data_sheets)\r\n\r\n}\r\n  \r\n# specifying the path and file named to be used in my function.  \r\n# execute the function\r\n\r\n\r\npath <- \"c:/users/theresa/Documents/DACSS Local/DataSets/australian_marriage_law_postal_survey_2017_-_response_final_mod.xls\"\r\nmultiplesheets(path)\r\n\r\n\r\n[1] \"Contents\"          \"Table 1\"           \"Table 2\"          \r\n[4] \"Explanatory Notes\"\r\n[[1]]\r\n# A tibble: 23 x 3\r\n   `Australian Bureau of Statistics`                  ...2       ...3 \r\n   <chr>                                              <chr>      <chr>\r\n 1 1800.0 Australian Marriage Law Postal Survey, 2017 <NA>       <NA> \r\n 2 Released on 15 November 2017                       <NA>       <NA> \r\n 3 <NA>                                               <NA>       <NA> \r\n 4 <NA>                                               Contents   <NA> \r\n 5 <NA>                                               Tables     <NA> \r\n 6 <NA>                                               Table 1    Resp~\r\n 7 <NA>                                               Table 2    Resp~\r\n 8 <NA>                                               <NA>       <NA> \r\n 9 <NA>                                               Explanato~ <NA> \r\n10 <NA>                                               <NA>       <NA> \r\n# ... with 13 more rows\r\n\r\n[[2]]\r\n# A tibble: 21 x 16\r\n   `Australian Burea~` ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 \r\n   <chr>               <chr> <chr> <chr> <chr> <chr> <chr> <lgl> <chr>\r\n 1 1800.0 Australian ~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 2 Released on 15 Nov~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 3 Table 1 Response b~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 4 <NA>                Resp~ <NA>  <NA>  <NA>  <NA>  <NA>  NA    Elig~\r\n 5 <NA>                Yes   <NA>  No    <NA>  Total <NA>  NA    Resp~\r\n 6 Country             no.   %     no.   %     no.   %     NA    no.  \r\n 7 New South Wales     2374~ 57.7~ 1736~ 42.2~ 4111~ 100   NA    4111~\r\n 8 Victoria            2145~ 64.9~ 1161~ 35.1~ 3306~ 100   NA    3306~\r\n 9 Queensland          1487~ 60.7~ 9610~ 39.2~ 2448~ 100   NA    2448~\r\n10 South Australia     5925~ 62.5  3562~ 37.5  9487~ 100   NA    9487~\r\n# ... with 11 more rows, and 7 more variables: ...10 <chr>,\r\n#   ...11 <chr>, ...12 <chr>, ...13 <chr>, ...14 <chr>, ...15 <chr>,\r\n#   ...16 <chr>\r\n\r\n[[3]]\r\n# A tibble: 190 x 16\r\n   `Australian Burea~` ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 \r\n   <chr>               <chr> <chr> <chr> <chr> <chr> <chr> <lgl> <chr>\r\n 1 1800.0 Australian ~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 2 Released on 15 Nov~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 3 Table 2 Response b~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 4 <NA>                Resp~ <NA>  <NA>  <NA>  <NA>  <NA>  NA    Elig~\r\n 5 <NA>                Yes   <NA>  No    <NA>  Total <NA>  NA    Resp~\r\n 6 Region              no.   %     no.   %     no.   %     NA    no.  \r\n 7 New South Wales Di~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 8 Banks               37736 44.8~ 46343 55.1~ 84079 100   NA    84079\r\n 9 Barton              37153 43.6~ 47984 56.3~ 85137 100   NA    85137\r\n10 Bennelong           42943 49.7~ 43215 50.2~ 86158 100   NA    86158\r\n# ... with 180 more rows, and 7 more variables: ...10 <chr>,\r\n#   ...11 <chr>, ...12 <chr>, ...13 <chr>, ...14 <chr>, ...15 <chr>,\r\n#   ...16 <chr>\r\n\r\n[[4]]\r\n# A tibble: 31 x 2\r\n   `Australian Bureau of Statistics`                  ...2            \r\n   <chr>                                              <chr>           \r\n 1 1800.0 Australian Marriage Law Postal Survey, 2017 <NA>            \r\n 2 Released on 15 November 2017                       <NA>            \r\n 3 <NA>                                               <NA>            \r\n 4 <NA>                                               Explanatory Not~\r\n 5 <NA>                                               <NA>            \r\n 6 <NA>                                               Australian Marr~\r\n 7 <NA>                                               <NA>            \r\n 8 <NA>                                               <NA>            \r\n 9 <NA>                                               Definitions     \r\n10 <NA>                                               <NA>            \r\n# ... with 21 more rows\r\n\r\nLoad and Clean Only Select Sheets Within Unclean Excel\r\nThis is loading only the 2 sheets within the Australian Marriage Data file that contain data. Then take the resulting data and perform a multi-step clean up using:\r\ncomplete.case to remove rows with NA\r\nSELECT() to remove the column with no data\r\nC() to rename the columns\r\n\r\n\r\n# getting info about all excel sheets\r\n\r\n  sheet_names <- readxl::excel_sheets(path)\r\n  print(sheet_names)\r\n\r\n\r\n[1] \"Contents\"          \"Table 1\"           \"Table 2\"          \r\n[4] \"Explanatory Notes\"\r\n\r\n# moving data from just the interesting sheets to their own data tables\r\n  \r\n  table_1_data <- readxl::read_excel(path, sheet = \"Table 1\")\r\n  table_2_data <- readxl::read_excel(path, sheet = \"Table 2\")\r\n  \r\n# Print the data as loaded to check the values\r\n  \r\n  print(table_1_data)\r\n\r\n\r\n# A tibble: 21 x 16\r\n   `Australian Burea~` ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 \r\n   <chr>               <chr> <chr> <chr> <chr> <chr> <chr> <lgl> <chr>\r\n 1 1800.0 Australian ~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 2 Released on 15 Nov~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 3 Table 1 Response b~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 4 <NA>                Resp~ <NA>  <NA>  <NA>  <NA>  <NA>  NA    Elig~\r\n 5 <NA>                Yes   <NA>  No    <NA>  Total <NA>  NA    Resp~\r\n 6 Country             no.   %     no.   %     no.   %     NA    no.  \r\n 7 New South Wales     2374~ 57.7~ 1736~ 42.2~ 4111~ 100   NA    4111~\r\n 8 Victoria            2145~ 64.9~ 1161~ 35.1~ 3306~ 100   NA    3306~\r\n 9 Queensland          1487~ 60.7~ 9610~ 39.2~ 2448~ 100   NA    2448~\r\n10 South Australia     5925~ 62.5  3562~ 37.5  9487~ 100   NA    9487~\r\n# ... with 11 more rows, and 7 more variables: ...10 <chr>,\r\n#   ...11 <chr>, ...12 <chr>, ...13 <chr>, ...14 <chr>, ...15 <chr>,\r\n#   ...16 <chr>\r\n\r\n  print(table_2_data)\r\n\r\n\r\n# A tibble: 190 x 16\r\n   `Australian Burea~` ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 \r\n   <chr>               <chr> <chr> <chr> <chr> <chr> <chr> <lgl> <chr>\r\n 1 1800.0 Australian ~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 2 Released on 15 Nov~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 3 Table 2 Response b~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 4 <NA>                Resp~ <NA>  <NA>  <NA>  <NA>  <NA>  NA    Elig~\r\n 5 <NA>                Yes   <NA>  No    <NA>  Total <NA>  NA    Resp~\r\n 6 Region              no.   %     no.   %     no.   %     NA    no.  \r\n 7 New South Wales Di~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 8 Banks               37736 44.8~ 46343 55.1~ 84079 100   NA    84079\r\n 9 Barton              37153 43.6~ 47984 56.3~ 85137 100   NA    85137\r\n10 Bennelong           42943 49.7~ 43215 50.2~ 86158 100   NA    86158\r\n# ... with 180 more rows, and 7 more variables: ...10 <chr>,\r\n#   ...11 <chr>, ...12 <chr>, ...13 <chr>, ...14 <chr>, ...15 <chr>,\r\n#   ...16 <chr>\r\n\r\n  # Beginning the clean up process\r\n  \r\n# 1) Remove the rows with no values using the complete.cases command.\r\n#    Print the data after the removal of the empty rows.\r\n    \r\n  table_1_data <- table_1_data[complete.cases(table_1_data[ , 3]),]\r\n  print(table_1_data)\r\n\r\n\r\n# A tibble: 10 x 16\r\n   `Australian Burea~` ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 \r\n   <chr>               <chr> <chr> <chr> <chr> <chr> <chr> <lgl> <chr>\r\n 1 Country             no.   %     no.   %     no.   %     NA    no.  \r\n 2 New South Wales     2374~ 57.7~ 1736~ 42.2~ 4111~ 100   NA    4111~\r\n 3 Victoria            2145~ 64.9~ 1161~ 35.1~ 3306~ 100   NA    3306~\r\n 4 Queensland          1487~ 60.7~ 9610~ 39.2~ 2448~ 100   NA    2448~\r\n 5 South Australia     5925~ 62.5  3562~ 37.5  9487~ 100   NA    9487~\r\n 6 Western Australia   8015~ 63.7~ 4559~ 36.2~ 1257~ 100   NA    1257~\r\n 7 Tasmania            1919~ 63.6~ 1096~ 36.3~ 3016~ 100   NA    3016~\r\n 8 Northern Territory~ 48686 60.6~ 31690 39.3~ 80376 100   NA    80376\r\n 9 Australian Capital~ 1754~ 74    61520 26    2369~ 100   NA    2369~\r\n10 Australia           7817~ 61.6~ 4873~ 38.3~ 1269~ 100   NA    1269~\r\n# ... with 7 more variables: ...10 <chr>, ...11 <chr>, ...12 <chr>,\r\n#   ...13 <chr>, ...14 <chr>, ...15 <chr>, ...16 <chr>\r\n\r\n  table_2_data <- table_2_data[complete.cases(table_2_data[ , 3]),]\r\n  print(table_2_data)\r\n\r\n\r\n# A tibble: 160 x 16\r\n   `Australian Burea~` ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 \r\n   <chr>               <chr> <chr> <chr> <chr> <chr> <chr> <lgl> <chr>\r\n 1 Region              no.   %     no.   %     no.   %     NA    no.  \r\n 2 Banks               37736 44.8~ 46343 55.1~ 84079 100   NA    84079\r\n 3 Barton              37153 43.6~ 47984 56.3~ 85137 100   NA    85137\r\n 4 Bennelong           42943 49.7~ 43215 50.2~ 86158 100   NA    86158\r\n 5 Berowra             48471 54.6~ 40369 45.3~ 88840 100   NA    88840\r\n 6 Blaxland            20406 26.1~ 57926 73.9~ 78332 100   NA    78332\r\n 7 Bradfield           53681 60.6~ 34927 39.3~ 88608 100   NA    88608\r\n 8 Calare              54091 60.2~ 35779 39.7~ 89870 100   NA    89870\r\n 9 Chifley             32871 41.2~ 46702 58.7~ 79573 100   NA    79573\r\n10 Cook                47505 55    38804 45    86309 100   NA    86309\r\n# ... with 150 more rows, and 7 more variables: ...10 <chr>,\r\n#   ...11 <chr>, ...12 <chr>, ...13 <chr>, ...14 <chr>, ...15 <chr>,\r\n#   ...16 <chr>\r\n\r\n# 2) Remove the empty column which happens to be column 8 on both sheets\r\n  \r\n  table_1_data <- select(table_1_data, -8)\r\n  table_2_data <- select(table_2_data, -8)\r\n  \r\n# 3) Rename the column headers to make the data clear. \r\n  \r\n  names(table_1_data) <- c('Region 1','Num Yes 1' , '% Yes 1', 'Num No 1', '% No 1', 'Num Total 1', '% Total 1','Clear Response 1', '% Clear Response 1', 'Not Clear Response 1', '% Not Clear Response 1','Total Response 1', '% Total 1')\r\n  \r\n  names(table_2_data) <- c('Region 2','Num Yes 2' , '% Yes 2', 'Num No 2', '% No 2', 'Num Total 2', '% Total 2','Clear Response 2', '% Clear Response 2', 'Not Clear Response 2', '% Not Clear Response 2', 'Not Responding 2', '% Not Responding 2', 'Total Response 2', '% Total 2')\r\n  \r\n#    Print the data after the removal of column and renaming of the columns.\r\n  \r\n  print(table_1_data)    \r\n\r\n\r\n# A tibble: 10 x 15\r\n   `Region 1`  `Num Yes 1` `% Yes 1` `Num No 1` `% No 1` `Num Total 1`\r\n   <chr>       <chr>       <chr>     <chr>      <chr>    <chr>        \r\n 1 Country     no.         %         no.        %        no.          \r\n 2 New South ~ 2374362     57.79999~ 1736838    42.2000~ 4111200      \r\n 3 Victoria    2145629     64.90000~ 1161098    35.1000~ 3306727      \r\n 4 Queensland  1487060     60.70000~ 961015     39.2999~ 2448075      \r\n 5 South Aust~ 592528      62.5      356247     37.5     948775       \r\n 6 Western Au~ 801575      63.70000~ 455924     36.2999~ 1257499      \r\n 7 Tasmania    191948      63.60000~ 109655     36.3999~ 301603       \r\n 8 Northern T~ 48686       60.60000~ 31690      39.3999~ 80376        \r\n 9 Australian~ 175459      74        61520      26       236979       \r\n10 Australia   7817247     61.60000~ 4873987    38.3999~ 12691234     \r\n# ... with 9 more variables: `% Total 1` <chr>,\r\n#   `Clear Response 1` <chr>, `% Clear Response 1` <chr>,\r\n#   `Not Clear Response 1` <chr>, `% Not Clear Response 1` <chr>,\r\n#   `Total Response 1` <chr>, `% Total 1` <chr>, `` <chr>, `` <chr>\r\n\r\n  print(table_2_data)\r\n\r\n\r\n# A tibble: 160 x 15\r\n   `Region 2` `Num Yes 2` `% Yes 2`  `Num No 2` `% No 2` `Num Total 2`\r\n   <chr>      <chr>       <chr>      <chr>      <chr>    <chr>        \r\n 1 Region     no.         %          no.        %        no.          \r\n 2 Banks      37736       44.899999~ 46343      55.1000~ 84079        \r\n 3 Barton     37153       43.600000~ 47984      56.3999~ 85137        \r\n 4 Bennelong  42943       49.799999~ 43215      50.2000~ 86158        \r\n 5 Berowra    48471       54.600000~ 40369      45.3999~ 88840        \r\n 6 Blaxland   20406       26.100000~ 57926      73.9000~ 78332        \r\n 7 Bradfield  53681       60.600000~ 34927      39.3999~ 88608        \r\n 8 Calare     54091       60.200000~ 35779      39.7999~ 89870        \r\n 9 Chifley    32871       41.299999~ 46702      58.7000~ 79573        \r\n10 Cook       47505       55         38804      45       86309        \r\n# ... with 150 more rows, and 9 more variables: `% Total 2` <chr>,\r\n#   `Clear Response 2` <chr>, `% Clear Response 2` <chr>,\r\n#   `Not Clear Response 2` <chr>, `% Not Clear Response 2` <chr>,\r\n#   `Not Responding 2` <chr>, `% Not Responding 2` <chr>,\r\n#   `Total Response 2` <chr>, `% Total 2` <chr>\r\n\r\n# 3) remove the total lines on table 2\r\n  \r\n  # Having trouble getting this to work.  \r\n  # table_2_data %>% filter(grepl('total', 1))\r\n  \r\n \r\n  \r\n    # remove any rows with the word \"Total\" in them\r\n    # table_2_data <- (!grep(\"Total\", table_2_data))\r\n    # print(table_2_data)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-13T15:56:43-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsshayehalleegithubiocoursework2022-02-12-dacss-601-hw02/",
    "title": "Shaye Hallee - DACSS 601 HW02",
    "description": "Reading in ACS 2019 disability population estimates.",
    "author": [
      {
        "name": "Shaye Hallee",
        "url": {}
      }
    ],
    "date": "2022-02-13",
    "categories": [],
    "contents": "\r\nIntroducing the data\r\nHere, we’ll be looking at data about disabled populations in US counties. Specifically, we’re using Subject Table S1810 from the 2019 1-year population estimates from the American Community Survey, an on-going demographics survey run by the U.S. Census Bureau. This table includes lots of data including county populations and disabled populations across different demographics.1\r\nWe’re going to answer the following questions:\r\nWhich US county has the highest disabled population (by count)?\r\nWhich county has the lowest disabled population (by count)?\r\nWhich counties have a much higher than average disabled population (by percentage)?\r\nWhich counties have a much lower than average disabled population (by percentage)?\r\nTable S1810 is incredibly large, so we’ll pull out the following columns:\r\nVariable\r\nClass\r\nDescription\r\nCounty\r\nchar (text)\r\ncounty name\r\nState\r\nchar (text)\r\nstate name\r\ncty_ni_pop\r\ndbl (numerical)\r\ntotal estimated 2019 county population of noninstitutionalized civilians\r\ncty_ni_dis_pop\r\ndbl (numerical)\r\nestimated 2019 county population of disabled, noninstitutionalized civilians\r\ncty_pct_disabled\r\ndbl (numerical)\r\ndisabled population as a percentage of the total county population\r\n“Noninstitutionalized civilians” means people who aren’t in the armed forces and don’t live in institutions like prisons, hospitals, or nursing homes.2 These other two groups usually rely on their respective institutions to meet their support and access needs, and they usually have higher disabled populations. Surveys like the ACS are mostly used to plan community resources, so they exclude these groups with the assumption that they won’t be interacting with the communities around them.3\r\nI might have to find more thorough data if I plan to use demographics information in future projects.\r\nReading in the data\r\nLet’s read the data in, free it from an unnecessary row, and put it all in a tibble.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(knitr)\r\n\r\ndata <- read.csv(\"ACS_ST_1Y_2019_Disability_County/data_all.csv\", encoding = \"UTF-8\")\r\ndata <- data[c(2:nrow(data)),]\r\ndata <- as_tibble(data)\r\n\r\n\r\n\r\nLet’s make sure it’s a tibble of about the expected size.\r\n\r\n\r\nclass(data)\r\n\r\n\r\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\r\n\r\ndim(data)\r\n\r\n\r\n[1] 840 416\r\n\r\nDone!\r\nCleaning up the data\r\nRight now, our tibble has a lot of very cool data that we won’t be using, and the column names aren’t human-friendly.\r\nLet’s extract the right columns and give them (marginally) friendlier names. We’ll use dplyr::select for that.\r\n\r\n\r\ndata <- select(data,\r\n               NAME,\r\n               cty_ni_pop = S1810_C01_001E,\r\n               cty_ni_dis_pop = S1810_C02_001E,\r\n               cty_pct_disabled = S1810_C03_001E)\r\n\r\n\r\n\r\nFor kicks, let’s separate the “NAME” column into “County” and “State.”\r\n\r\n\r\ndata <- separate(data, NAME, c(\"County\", \"State\"), sep = \", \")\r\n\r\n\r\n\r\nLet’s turn the appropriate columns into numerical values. This is kind of sloppy, but it’s just three columns in a script we probably won’t use again. Famous last words, I know.\r\n\r\n\r\ndata$cty_ni_pop <- as.numeric(data$cty_ni_pop)\r\ndata$cty_ni_dis_pop <- as.numeric(data$cty_ni_dis_pop)\r\ndata$cty_pct_disabled <- as.numeric(data$cty_pct_disabled)\r\n\r\n\r\n\r\nHere’s what the data looks like now:\r\n\r\n\r\nkable(head(data))\r\n\r\n\r\nCounty\r\nState\r\ncty_ni_pop\r\ncty_ni_dis_pop\r\ncty_pct_disabled\r\nBaldwin County\r\nAlabama\r\n220911\r\n31901\r\n14.4\r\nCalhoun County\r\nAlabama\r\n111075\r\n22269\r\n20.0\r\nCullman County\r\nAlabama\r\n82841\r\n14480\r\n17.5\r\nDeKalb County\r\nAlabama\r\n70392\r\n7583\r\n10.8\r\nElmore County\r\nAlabama\r\n75409\r\n9707\r\n12.9\r\nEtowah County\r\nAlabama\r\n101470\r\n15944\r\n15.7\r\n\r\nkable(tail(data))\r\n\r\n\r\nCounty\r\nState\r\ncty_ni_pop\r\ncty_ni_dis_pop\r\ncty_pct_disabled\r\nMayagüez Municipio\r\nPuerto Rico\r\n71018\r\n15705\r\n22.1\r\nPonce Municipio\r\nPuerto Rico\r\n129198\r\n28785\r\n22.3\r\nSan Juan Municipio\r\nPuerto Rico\r\n313915\r\n60014\r\n19.1\r\nToa Alta Municipio\r\nPuerto Rico\r\n71897\r\n6140\r\n8.5\r\nToa Baja Municipio\r\nPuerto Rico\r\n73735\r\n16284\r\n22.1\r\nTrujillo Alto Municipio\r\nPuerto Rico\r\n63312\r\n15870\r\n25.1\r\n\r\nFinding cool things in the data\r\nFirst, let’s find the average disabled population in a US county, as a percentage of the total population.\r\n\r\n\r\nmean_pct_disabled <- mean(data$cty_pct_disabled)\r\nmean_pct_disabled\r\n\r\n\r\n[1] 13.70964\r\n\r\nWe’ll use dplyr::filter to answer the questions from the intro.\r\nWhich US county has the highest disabled population (by count)?\r\n\r\n\r\nhighest_disabled_pop <- filter(data, (data$cty_ni_dis_pop == max(data$cty_ni_dis_pop)))\r\nkable(highest_disabled_pop)\r\n\r\n\r\nCounty\r\nState\r\ncty_ni_pop\r\ncty_ni_dis_pop\r\ncty_pct_disabled\r\nLos Angeles County\r\nCalifornia\r\n9964081\r\n984931\r\n9.9\r\n\r\nWhich county has the lowest disabled population (by count)?\r\n\r\n\r\nlowest_disabled_pop <- filter(data, (data$cty_ni_dis_pop == min(data$cty_ni_dis_pop)))\r\nkable(lowest_disabled_pop)\r\n\r\n\r\nCounty\r\nState\r\ncty_ni_pop\r\ncty_ni_dis_pop\r\ncty_pct_disabled\r\nWalker County\r\nTexas\r\n61093\r\n4947\r\n8.1\r\n\r\nWhich counties have a much higher than average disabled population (by percentage)? Let’s arbitrarily use 1.75 times the mean as our threshold.\r\n\r\n\r\nhi_disability <- filter(data, data$cty_pct_disabled >= 1.75*mean_pct_disabled)\r\nkable(hi_disability)\r\n\r\n\r\nCounty\r\nState\r\ncty_ni_pop\r\ncty_ni_dis_pop\r\ncty_pct_disabled\r\nTalladega County\r\nAlabama\r\n76722\r\n20102\r\n26.2\r\nWalker County\r\nAlabama\r\n62896\r\n17381\r\n27.6\r\nCharlotte County\r\nFlorida\r\n186002\r\n45368\r\n24.4\r\nWalker County\r\nGeorgia\r\n68199\r\n16593\r\n24.3\r\nRaleigh County\r\nWest Virginia\r\n70907\r\n17130\r\n24.2\r\nBayamón Municipio\r\nPuerto Rico\r\n164521\r\n43015\r\n26.1\r\nCaguas Municipio\r\nPuerto Rico\r\n124149\r\n32099\r\n25.9\r\nGuaynabo Municipio\r\nPuerto Rico\r\n83119\r\n19948\r\n24.0\r\nTrujillo Alto Municipio\r\nPuerto Rico\r\n63312\r\n15870\r\n25.1\r\n\r\nWhich counties have a much lower than average disabled population (by percentage)? Let’s (also arbitrarily) use 0.5 times the mean as our threshold.\r\n\r\n\r\nlo_disability <- filter(data, data$cty_pct_disabled <= 0.5*mean_pct_disabled)\r\nkable(lo_disability)\r\n\r\n\r\nCounty\r\nState\r\ncty_ni_pop\r\ncty_ni_dis_pop\r\ncty_pct_disabled\r\nGwinnett County\r\nGeorgia\r\n930955\r\n63740\r\n6.8\r\nCarver County\r\nMinnesota\r\n104708\r\n6822\r\n6.5\r\nFort Bend County\r\nTexas\r\n806384\r\n53265\r\n6.6\r\nArlington County\r\nVirginia\r\n231652\r\n14506\r\n6.3\r\nLoudoun County\r\nVirginia\r\n411654\r\n23713\r\n5.8\r\nAlexandria city\r\nVirginia\r\n155298\r\n10181\r\n6.6\r\n\r\nWhat’s next?\r\nNone of this tells us anything particularly interesting without looking at some complementary data. I’d be interested in looking at other data from Subject Table S1810 to see if there are correlations with race, overall population size, age, or type of disability. Other data sets are out there with data on poverty, food access, urbanization, and lots of other information, and it’ll be very cool to check out some of that data.\r\n\r\nU.S. Census Bureau, 2019 American Community Survey 1-Year Estimates, https://data.census.gov/cedsci/table?t=Disability&tid=ACSST1Y2019.S1810↩︎\r\nU.S. Census Bureau, American Community Survey and Puerto Rico Community Survey 2019 Code List, https://www2.census.gov/programs-surveys/acs/tech_docs/code_lists/2019_ACS_Code_Lists.pdf↩︎\r\nBrault, M. (2008). Disability Status and the Characteristics of People in Group Quarters: A Brief Analysis of Disability Prevalence Among the Civilian Noninstitutionalized and Total Populations in the American Community Survey. U.S. Census Bureau “Working Papers”. https://www.census.gov/library/working-papers/2008/demo/brault-01.html↩︎\r\n",
    "preview": {},
    "last_modified": "2022-02-13T15:57:19-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-02-example-pivot-longer/",
    "title": "Example Code for Pivot Longer",
    "description": "I'm sharing some example code for pivot_longer using the eggs data. Enjoy!",
    "author": [
      {
        "name": "Meredith Rolfe",
        "url": {
          "https://www.umass.edu/sbs/data-analytics-and-computational-social-science-program": {}
        }
      }
    ],
    "date": "2022-02-11",
    "categories": [
      "example code",
      "data cleaning"
    ],
    "contents": "\nThis is example code for using the pivot functions in R. Several of the government data sources include tabular data that really need to be pivoted into a dataset in which a “case” is some combination of the grouping variables (the rows and columns in the table) alongside the appropriate statistical value(s) in the table (e.g., counts or average costs). Lets start with the easy to read in eggs_tidy.csv just so we can focus on the pivoting function.\n\n\neggs<-read_csv(\"../../_data/eggs_tidy.csv\", show_col_types = FALSE)\neggs\n\n\n# A tibble: 120 × 6\n   month      year large_half_dozen large_dozen extra_large_half_dozen\n   <chr>     <dbl>            <dbl>       <dbl>                  <dbl>\n 1 January    2004             126         230                    132 \n 2 February   2004             128.        226.                   134.\n 3 March      2004             131         225                    137 \n 4 April      2004             131         225                    137 \n 5 May        2004             131         225                    137 \n 6 June       2004             134.        231.                   137 \n 7 July       2004             134.        234.                   137 \n 8 August     2004             134.        234.                   137 \n 9 September  2004             130.        234.                   136.\n10 October    2004             128.        234.                   136.\n# … with 110 more rows, and 1 more variable: extra_large_dozen <dbl>\n\nLooking at the data, we can see that each case consists of a year-month combination (e.g., January 2004), while the values are the average price (in cents) of four different types of eggs (e.g., large_half_dozen, large_dozen, etc) But really, wouldn’t it possibly make more sense to consider the case as a year-month-type combination, with a single price value for each case?\nPivot Longer - One New Category Variable\nTo do this (and make our data easier to graph and analyze), we can pivot longer - changing our data from 120 rows with 6 variables (2 grouping and 4 values) to 480 rows of 4 variables (with 3 grouping variables and a single price value).\n\n\neggs%>%\n  pivot_longer(cols=large_half_dozen:extra_large_dozen, \n               names_to = \"eggType\",\n               values_to = \"avgPrice\"\n  )\n\n\n# A tibble: 480 × 4\n   month     year eggType                avgPrice\n   <chr>    <dbl> <chr>                     <dbl>\n 1 January   2004 large_half_dozen           126 \n 2 January   2004 large_dozen                230 \n 3 January   2004 extra_large_half_dozen     132 \n 4 January   2004 extra_large_dozen          230 \n 5 February  2004 large_half_dozen           128.\n 6 February  2004 large_dozen                226.\n 7 February  2004 extra_large_half_dozen     134.\n 8 February  2004 extra_large_dozen          230 \n 9 March     2004 large_half_dozen           131 \n10 March     2004 large_dozen                225 \n# … with 470 more rows\n\nWell, that was super easy. But wait, what if you are interested in egg size - you want to know how much more expensive extra-large eggs are compared to large eggs. Right now, that will be annoying, as you will have to keep sorting out the egg quantity - whether the price is for a half_dozen or a dozen eggs. Wouldn’t it be nice if we didn’t have a long egg type column with both size and quantity squashed into a single categorical variable? It would be so useful to have a new dataset with 4 grouping variables (year, month, size, and quantity) and the same value (price).\nPivot Longer - Two New Category Variables\nSo, once again we want to use pivot longer, but we will be adding two new category variables (for a total of 4) and this will cut the number of rows in half (to 240). But how in the world can we let R know what we want it to do?? Thankfully, someone named the egg types (column-names) pretty systematically, but how can use this to our advantage? Working with patterns in the names_sep option of the pivot functions makes it pretty easy (well, except our variable names have more than one underscore, so we have to sort of hack this part by also using mutate on the resulting category labels.)\n\n\neggs%>%\n  pivot_longer(cols=large_half_dozen:extra_large_dozen,\n               names_to = c(\"size\", \"quantity\"),\n               names_sep=\"arge_\",\n               values_to = \"price\"\n  ) %>%\n  mutate(size = case_when(\n    size == \"l\" ~ \"Large\",\n    size == \"extra_l\" ~ \"Extra Large\"\n  ))\n\n\n# A tibble: 480 × 5\n   month     year size        quantity   price\n   <chr>    <dbl> <chr>       <chr>      <dbl>\n 1 January   2004 Large       half_dozen  126 \n 2 January   2004 Large       dozen       230 \n 3 January   2004 Extra Large half_dozen  132 \n 4 January   2004 Extra Large dozen       230 \n 5 February  2004 Large       half_dozen  128.\n 6 February  2004 Large       dozen       226.\n 7 February  2004 Extra Large half_dozen  134.\n 8 February  2004 Extra Large dozen       230 \n 9 March     2004 Large       half_dozen  131 \n10 March     2004 Large       dozen       225 \n# … with 470 more rows\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-11T22:05:47-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httprpubscomikennedy040hw1/",
    "title": "HW1",
    "description": "1st HW assignment for DACSS 601.",
    "author": [
      {
        "name": "Ian Kennedy",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:02-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httprpubscomsnehalhw2/",
    "title": "DACSS 601 HW2",
    "description": "Reading in Data",
    "author": [
      {
        "name": "Snehal Prabhu",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\nRailroad Data\r\n\r\n\r\nlibrary(readr)\r\nlibrary(tidyverse)\r\ndata <- read_csv(\"601/railroad_2012_clean_state.csv\")\r\ncolnames(data)\r\n\r\n\r\n[1] \"state\"           \"total_employees\"\r\n\r\nhead(data)\r\n\r\n\r\n# A tibble: 6 x 2\r\n  state total_employees\r\n  <chr>           <dbl>\r\n1 AE                  2\r\n2 AK                103\r\n3 AL               4257\r\n4 AP                  1\r\n5 AR               3871\r\n6 AZ               3153\r\n\r\nData wrangling Operation\r\n\r\n\r\n# filter data with the number of employees and then arrange in decreasing order\r\nfilter(data,total_employees>10000) %>%\r\n  arrange(desc(total_employees)) \r\n\r\n\r\n# A tibble: 6 x 2\r\n  state total_employees\r\n  <chr>           <dbl>\r\n1 TX              19839\r\n2 IL              19131\r\n3 NY              17050\r\n4 NE              13176\r\n5 CA              13137\r\n6 PA              12769\r\n\r\nReading unclean excel data\r\n\r\n\r\nlibrary(readxl)\r\nexceldata <- read_excel(\"601/StateCounty2012.xls\", skip=3)\r\ncolnames(exceldata)\r\n\r\n\r\n[1] \"STATE\"  \"...2\"   \"COUNTY\" \"...4\"   \"TOTAL\" \r\n\r\nhead(exceldata)\r\n\r\n\r\n# A tibble: 6 x 5\r\n  STATE     ...2  COUNTY               ...4  TOTAL\r\n  <chr>     <lgl> <chr>                <lgl> <dbl>\r\n1 AE        NA    APO                  NA        2\r\n2 AE Total1 NA    <NA>                 NA        2\r\n3 AK        NA    ANCHORAGE            NA        7\r\n4 AK        NA    FAIRBANKS NORTH STAR NA        2\r\n5 AK        NA    JUNEAU               NA        3\r\n6 AK        NA    MATANUSKA-SUSITNA    NA        2\r\n\r\nData wrangling Operation\r\n\r\n\r\nlibrary(tidyr)\r\nexceldata <- exceldata %>%\r\n  select(\"STATE\",\"COUNTY\",\"TOTAL\") %>%\r\n  drop_na(\"COUNTY\")\r\nhead(exceldata)\r\n\r\n\r\n# A tibble: 6 x 3\r\n  STATE COUNTY               TOTAL\r\n  <chr> <chr>                <dbl>\r\n1 AE    APO                      2\r\n2 AK    ANCHORAGE                7\r\n3 AK    FAIRBANKS NORTH STAR     2\r\n4 AK    JUNEAU                   3\r\n5 AK    MATANUSKA-SUSITNA        2\r\n6 AK    SITKA                    1\r\n\r\naggregate(x=exceldata$TOTAL, by=list(exceldata$STATE), FUN=sum)\r\n\r\n\r\n   Group.1     x\r\n1       AE     2\r\n2       AK   103\r\n3       AL  4257\r\n4       AP     1\r\n5       AR  3871\r\n6       AZ  3153\r\n7       CA 13137\r\n8       CO  3650\r\n9       CT  2592\r\n10      DC   279\r\n11      DE  1495\r\n12      FL  7419\r\n13      GA  8605\r\n14      HI     4\r\n15      IA  4019\r\n16      ID  1563\r\n17      IL 19131\r\n18      IN  8537\r\n19      KS  6092\r\n20      KY  4811\r\n21      LA  3915\r\n22      MA  3379\r\n23      MD  4709\r\n24      ME   654\r\n25      MI  3932\r\n26      MN  5467\r\n27      MO  8419\r\n28      MS  2111\r\n29      MT  3327\r\n30      NC  3143\r\n31      ND  2204\r\n32      NE 13176\r\n33      NH   393\r\n34      NJ  8329\r\n35      NM  1958\r\n36      NV   746\r\n37      NY 17050\r\n38      OH  9056\r\n39      OK  2318\r\n40      OR  2322\r\n41      PA 12769\r\n42      RI   487\r\n43      SC  2296\r\n44      SD   949\r\n45      TN  4952\r\n46      TX 19839\r\n47      UT  1917\r\n48      VA  7551\r\n49      VT   259\r\n50      WA  5222\r\n51      WI  3773\r\n52      WV  3213\r\n53      WY  2876\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:39-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsdamionperrygithubiodcss601posts/",
    "title": "Homework 2",
    "description": "Reading in .xls data & doing a bit of tidying!",
    "author": [
      {
        "name": "Damion Perry",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\nThe following is data summarizing the US Railroad employment numbers from 2012.\n‘state’\ntype -> character string Represents the state that railroad employees worked.\n‘county’\ntype -> character string Represents the county within the corresponding state.\n‘num_employees’\ntype -> dbl Number of employees working for the railroad in the corresponding state and county.\nTidy & Wrangle\nThe original dataset has been modified to display the results for US railroad employment in Massachusetts.\n\n\nlibrary(readxl)\nStateCounty2012 <- read_excel(\"HW2/StateCounty2012.xlsx\", skip = 2)\nstate_county <- StateCounty2012[c(1,3,5)]\nstate_county %>% \n  rename(state = STATE, county = COUNTY, num_employees = TOTAL) %>%\n  drop_na(county) %>% \n  filter(state == \"MA\") %>% \n  arrange(desc(num_employees))\n\n\n# A tibble: 12 × 3\n   state county     num_employees\n   <chr> <chr>              <dbl>\n 1 MA    MIDDLESEX            673\n 2 MA    SUFFOLK              558\n 3 MA    PLYMOUTH             429\n 4 MA    NORFOLK              386\n 5 MA    ESSEX                314\n 6 MA    WORCESTER            310\n 7 MA    BRISTOL              232\n 8 MA    HAMPDEN              202\n 9 MA    FRANKLIN             113\n10 MA    HAMPSHIRE             68\n11 MA    BERKSHIRE             50\n12 MA    BARNSTABLE            44\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-09T18:38:05-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomahungundaphhw12/",
    "title": "HW1 - Attempt #2",
    "description": "DACSS 601 Data Science Fundamentals - Homework 1",
    "author": [
      {
        "name": "Apoorva Hungund",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-09T18:36:51-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomamarkowitzhw1/",
    "title": "HW1",
    "description": "Already messed up the first homework",
    "author": [
      {
        "name": "Ari Markowitz",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\nR Markdown\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\n\nsummary(cars)\n\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \n\nIncluding Plots\nYou can also embed plots, for example:\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot.\n\n\n\n",
    "preview": "posts/httpsrpubscomamarkowitzhw1/distill-preview.png",
    "last_modified": "2022-02-09T18:37:12-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomamarkowitzhw2/",
    "title": "HW2",
    "description": "This is Homework 2! Pulling JSON data from USDA food data website",
    "author": [
      {
        "name": "Ari Markowitz",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\nSetup\n\n\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(httr)\nlibrary(jsonlite)\nknitr::opts_knit$set(root.dir = \"/Users/Lion_1/Desktop/DACSS/601/Datasets\")\n\n\n\nRead Food Data from API Key\nAPI has 200 item limit per call, iterate 50 times over pageNumber to generate dataset of 1000 items:\n\n\n#API KEY: CUz3HomE1xtius6ZtxNx4MnWny9tgvYT0mWS4HDb\ni<-1\nfoodlist <- list()\nwhile (i<=50){\n  if (i==1){\n      foodlist<- fromJSON(rawToChar(GET(paste(\"https://api.nal.usda.gov/fdc/v1/foods/list?api_key=CUz3HomE1xtius6ZtxNx4MnWny9tgvYT0mWS4HDb&&pageNumber=\",1,\"&&PageSize=200\",sep=\"\"))$content))\n  }else{\n    foodlist <-rbind(foodlist,fromJSON(rawToChar(GET(paste(\"https://api.nal.usda.gov/fdc/v1/foods/list?api_key=CUz3HomE1xtius6ZtxNx4MnWny9tgvYT0mWS4HDb&&pageNumber=\",1,\"&&PageSize=200\",sep=\"\"))$content)))\n  }\ni <- i+1\n}\n\n\n\nClean Up Data\nData contains nested tables, pull them out:\n\n\nfoodlist <- foodlist %>% unnest(cols = c(foodNutrients)) %>% rename(measureID = number, measureName = name, value = amount )\nprint(head(foodlist))\n\n\n# A tibble: 6 × 12\n    fdcId description   dataType    publicationDate foodCode measureID\n    <int> <chr>         <chr>       <chr>           <chr>    <chr>    \n1 1104067 100 GRAND Bar Survey (FN… 2020-10-30      91715300 203      \n2 1104067 100 GRAND Bar Survey (FN… 2020-10-30      91715300 204      \n3 1104067 100 GRAND Bar Survey (FN… 2020-10-30      91715300 205      \n4 1104067 100 GRAND Bar Survey (FN… 2020-10-30      91715300 208      \n5 1104067 100 GRAND Bar Survey (FN… 2020-10-30      91715300 221      \n6 1104067 100 GRAND Bar Survey (FN… 2020-10-30      91715300 255      \n# … with 6 more variables: measureName <chr>, value <dbl>,\n#   unitName <chr>, derivationCode <chr>,\n#   derivationDescription <chr>, ndbNumber <chr>\n\nDescribe the data:\n\n\nstr(foodlist)\n\n\ntibble [600,800 × 12] (S3: tbl_df/tbl/data.frame)\n $ fdcId                : int [1:600800] 1104067 1104067 1104067 1104067 1104067 1104067 1104067 1104067 1104067 1104067 ...\n $ description          : chr [1:600800] \"100 GRAND Bar\" \"100 GRAND Bar\" \"100 GRAND Bar\" \"100 GRAND Bar\" ...\n $ dataType             : chr [1:600800] \"Survey (FNDDS)\" \"Survey (FNDDS)\" \"Survey (FNDDS)\" \"Survey (FNDDS)\" ...\n $ publicationDate      : chr [1:600800] \"2020-10-30\" \"2020-10-30\" \"2020-10-30\" \"2020-10-30\" ...\n $ foodCode             : chr [1:600800] \"91715300\" \"91715300\" \"91715300\" \"91715300\" ...\n $ measureID            : chr [1:600800] \"203\" \"204\" \"205\" \"208\" ...\n $ measureName          : chr [1:600800] \"Protein\" \"Total lipid (fat)\" \"Carbohydrate, by difference\" \"Energy\" ...\n $ value                : num [1:600800] 2.5 19.3 71 468 0 6.1 8 55 51.9 1 ...\n $ unitName             : chr [1:600800] \"G\" \"G\" \"G\" \"KCAL\" ...\n $ derivationCode       : chr [1:600800] NA NA NA NA ...\n $ derivationDescription: chr [1:600800] NA NA NA NA ...\n $ ndbNumber            : chr [1:600800] NA NA NA NA ...\n\nSort data by Measure ID:\n\n\nfoodlist <- foodlist %>% arrange(measureID)\n\n\n\nCreate a list of datasets, one for each dataType:\n\n\ndataTypes <- distinct(foodlist,dataType)\nfoodlist_by_dataType <- list()\nfor (i in seq_along(dataTypes[[1]])){\n  foodlist_by_dataType[[i]] <- foodlist %>% filter(dataType == dataTypes[[1]][i])\n}\nhead(foodlist_by_dataType)\n\n\n[[1]]\n# A tibble: 13,950 × 12\n     fdcId description     dataType publicationDate foodCode measureID\n     <int> <chr>           <chr>    <chr>           <chr>    <chr>    \n 1 1999631 Almond milk, u… Foundat… 2021-10-28      <NA>     \"\"       \n 2 1999631 Almond milk, u… Foundat… 2021-10-28      <NA>     \"\"       \n 3 1999631 Almond milk, u… Foundat… 2021-10-28      <NA>     \"\"       \n 4 1999631 Almond milk, u… Foundat… 2021-10-28      <NA>     \"\"       \n 5 1999631 Almond milk, u… Foundat… 2021-10-28      <NA>     \"\"       \n 6 1999631 Almond milk, u… Foundat… 2021-10-28      <NA>     \"\"       \n 7 1999631 Almond milk, u… Foundat… 2021-10-28      <NA>     \"\"       \n 8 1999631 Almond milk, u… Foundat… 2021-10-28      <NA>     \"\"       \n 9 1999631 Almond milk, u… Foundat… 2021-10-28      <NA>     \"\"       \n10 1999631 Almond milk, u… Foundat… 2021-10-28      <NA>     \"\"       \n# … with 13,940 more rows, and 6 more variables: measureName <chr>,\n#   value <dbl>, unitName <chr>, derivationCode <chr>,\n#   derivationDescription <chr>, ndbNumber <chr>\n\n[[2]]\n# A tibble: 256,750 × 12\n     fdcId description     dataType publicationDate foodCode measureID\n     <int> <chr>           <chr>    <chr>           <chr>    <chr>    \n 1 1104067 100 GRAND Bar   Survey … 2020-10-30      91715300 203      \n 2 1104086 3 MUSKETEERS B… Survey … 2020-10-30      91726420 203      \n 3 1104087 3 Musketeers T… Survey … 2020-10-30      91726425 203      \n 4 1099098 Abalone, cooke… Survey … 2020-10-30      26301110 203      \n 5 1099099 Abalone, flour… Survey … 2020-10-30      26301140 203      \n 6 1099100 Abalone, steam… Survey … 2020-10-30      26301160 203      \n 7 1102193 Adobo, with no… Survey … 2020-10-30      58137300 203      \n 8 1102343 Adobo, with ri… Survey … 2020-10-30      58150530 203      \n 9 1103957 Agave liquid s… Survey … 2020-10-30      91302020 203      \n10 1101164 Air filled fri… Survey … 2020-10-30      53420300 203      \n# … with 256,740 more rows, and 6 more variables: measureName <chr>,\n#   value <dbl>, unitName <chr>, derivationCode <chr>,\n#   derivationDescription <chr>, ndbNumber <chr>\n\n[[3]]\n# A tibble: 330,100 × 12\n    fdcId description      dataType publicationDate foodCode measureID\n    <int> <chr>            <chr>    <chr>           <chr>    <chr>    \n 1 167782 Abiyuch, raw     SR Lega… 2019-04-01      <NA>     203      \n 2 171687 Acerola juice, … SR Lega… 2019-04-01      <NA>     203      \n 3 171686 Acerola, (west … SR Lega… 2019-04-01      <NA>     203      \n 4 168061 Acorn stew (Apa… SR Lega… 2019-04-01      <NA>     203      \n 5 168992 Agave, cooked (… SR Lega… 2019-04-01      <NA>     203      \n 6 168993 Agave, dried (S… SR Lega… 2019-04-01      <NA>     203      \n 7 169814 Agave, raw (Sou… SR Lega… 2019-04-01      <NA>     203      \n 8 169823 Agutuk, fish wi… SR Lega… 2019-04-01      <NA>     203      \n 9 168976 Agutuk, fish/be… SR Lega… 2019-04-01      <NA>     203      \n10 168977 Agutuk, meat-ca… SR Lega… 2019-04-01      <NA>     203      \n# … with 330,090 more rows, and 6 more variables: measureName <chr>,\n#   value <dbl>, unitName <chr>, derivationCode <chr>,\n#   derivationDescription <chr>, ndbNumber <chr>\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:45-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomaristotle1862605/",
    "title": "HW2",
    "description": "Data set - hotel- Includes numeric data regarding cancellations, arrival times, dates (MO, year, day), and cancellations.",
    "author": [
      {
        "name": "Nora Jones",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\nhotel <- read_csv(file=“hotel_bookings.csv”) hotel dim(hotel) arrange (hotel, desc(lead_time)) filter(hotel, lead_time > 100)\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:28-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomcbonney862319/",
    "title": "HW01 Christa Bonney test 2",
    "description": "publishing with Rpub test",
    "author": [
      {
        "name": "Christa Bonney",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:08-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomenoh860308/",
    "title": "HW1",
    "description": "This is an example of RMarkdown.",
    "author": [
      {
        "name": "Eunsol Noh",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:22-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomethancampbell864073/",
    "title": "Ethan Campbell HW2",
    "description": "Importing clean dataset into R.",
    "author": [
      {
        "name": "Ethan campbell",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\nImporting dataset in as Poultry and inspecting the data.\r\nHere we notice we different types of data and the dimensions. Product is a character, year is an integer, month is character, and Price_dollar is a double class with numeric data and decimals.\r\n\r\n\r\nPoultry <- read.csv(\"poultry_tidy.csv\")\r\ncolnames(Poultry)\r\n\r\n\r\n[1] \"Product\"      \"Year\"         \"Month\"        \"Price_Dollar\"\r\n\r\ndim(Poultry)\r\n\r\n\r\n[1] 600   4\r\n\r\nhead(Poultry)\r\n\r\n\r\n  Product Year    Month Price_Dollar\r\n1   Whole 2013  January        2.385\r\n2   Whole 2013 February        2.385\r\n3   Whole 2013    March        2.385\r\n4   Whole 2013    April        2.385\r\n5   Whole 2013      May        2.385\r\n6   Whole 2013     June        2.385\r\n\r\nBeginning to analyze and adjust the data.\r\nUsing filter and arrange on the data to filter out the lower cost items then placing price and year in descending order.With this we are able to view which items are higher in price and sort them by year and month.There are two functions however, one displays the top five of the table and the second one displays the last five of the table.\r\n\r\n\r\ndata(Poultry)\r\nPoultry %>%\r\n  filter(Price_Dollar > 3) %>%\r\n  arrange(desc(Price_Dollar, Year)) %>%\r\n  head()\r\n\r\n\r\n     Product Year    Month Price_Dollar\r\n1 B/S Breast 2013  January       7.0375\r\n2 B/S Breast 2013 February       7.0375\r\n3 B/S Breast 2013    March       7.0375\r\n4 B/S Breast 2013    April       7.0375\r\n5 B/S Breast 2013      May       7.0375\r\n6 B/S Breast 2013     June       7.0375\r\n\r\ndata(Poultry)\r\nPoultry %>%\r\n  filter(Price_Dollar > 3) %>%\r\n  arrange(desc(Price_Dollar, Year)) %>%\r\n  tail()\r\n\r\n\r\n           Product Year     Month Price_Dollar\r\n229 Bone-in Breast 2004      July        3.905\r\n230 Bone-in Breast 2004    August        3.905\r\n231 Bone-in Breast 2004 September        3.905\r\n232 Bone-in Breast 2004   October        3.905\r\n233 Bone-in Breast 2004  November        3.905\r\n234 Bone-in Breast 2004  December        3.905\r\n\r\nUsing filter and arrange\r\nThis will filter out the higher cost items and then placing year and price in descending order. With this information we can accuratly track the price change for each item by month and year. Once more using two equations to display the top five and the bottom five.\r\n\r\n\r\nPoultry %>%\r\n  filter(Price_Dollar < 3) %>%\r\n  arrange(desc(Year, Price_Dollar)) %>%\r\n  head()\r\n\r\n\r\n  Product Year    Month Price_Dollar\r\n1   Whole 2013  January        2.385\r\n2   Whole 2013 February        2.385\r\n3   Whole 2013    March        2.385\r\n4   Whole 2013    April        2.385\r\n5   Whole 2013      May        2.385\r\n6   Whole 2013     June        2.385\r\n\r\nPoultry %>%\r\n  filter(Price_Dollar < 3) %>%\r\n  arrange(desc(Year, Price_Dollar)) %>%\r\n  tail()\r\n\r\n\r\n    Product Year     Month Price_Dollar\r\n354  Thighs 2004      July        1.995\r\n355  Thighs 2004    August        1.995\r\n356  Thighs 2004 September        1.995\r\n357  Thighs 2004   October        1.995\r\n358  Thighs 2004  November        1.995\r\n359  Thighs 2004  December        1.995\r\n\r\nVisulaization\r\nWe assign the cheaper products to Cheap_poultry so we can utilize this function inside of a graph. After visualizing a smooth graph we can see the peak price for cheap products under $3 was in 2009. In the expenisive poultry we notice a major dip in prices in 2008 when there was a crash.\r\n\r\n\r\nPoultry %>%\r\n  filter(Price_Dollar < 3) %>%\r\n  arrange(desc(Year, Price_Dollar)) -> Cheap_poultry\r\n\r\nggplot(data = Cheap_poultry) +\r\n  geom_smooth(mapping = aes(x = Year, y = Price_Dollar), se = FALSE)\r\n\r\n\r\n\r\nPoultry %>%\r\n  filter(Price_Dollar > 3) %>%\r\n  arrange(desc(Year, Price_Dollar)) -> expensive_poultry\r\n\r\n\r\nggplot(data = expensive_poultry) +\r\n  geom_smooth(mapping = aes(x = Year, y = Price_Dollar), se = FALSE)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/httpsrpubscomethancampbell864073/distill-preview.png",
    "last_modified": "2022-02-09T18:37:59-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomgamez654862790/",
    "title": "HW1",
    "description": "Rmd Resubmission",
    "author": [
      {
        "name": "Alexis Gamez",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\nRpubs Test Post\r\nThis document serves as a test post to ensure that I am able to post and save Markdowns correctly.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:36-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomgamez654863847/",
    "title": "HW 2",
    "description": "Reading in & tidying data",
    "author": [
      {
        "name": "Alexis Gamez",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\nSetup\r\nSetting up R so that xlsx files/data can be read into the program and tidyverse packages are active.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(readxl)\r\n\r\n\r\n\r\nReading in the Data\r\nImported data from the xlsx file by navigating the “Files” tab under the plots pane. While you can include all data as is, I excluded the top 8 rows to tidy the data a bit. This can also be done using code as shown in the chunk below. Also, note that in the same chunk, I’ve renamed the original file name from “ActiveDuty_MaritalStatus” to “Marital_Status”. This data set only takes into account the 1st sheet within the excel file that was used for reference.\r\n\r\n\r\nActiveDuty_MaritalStatus <- read_excel(\"HW2/ActiveDuty_MaritalStatus.xlsx\", skip = 8)\r\nMarital_Status <- ActiveDuty_MaritalStatus\r\n\r\n#Confirming that the data set was renamed correctly\r\nMarital_Status\r\n\r\n\r\n# A tibble: 30 x 17\r\n   ...1  `Pay Grade` Male...3 Female...4 Total...5 Male...6 Female...7\r\n   <chr> <chr>          <dbl>      <dbl>     <dbl>    <dbl>      <dbl>\r\n 1 <NA>  E-1            31229       5717     36946      563        122\r\n 2 <NA>  E-2            53094       8388     61482     1457        275\r\n 3 <NA>  E-3           131091      21019    152110     4264       1920\r\n 4 <NA>  E-4           112710      16381    129091     9491       4662\r\n 5 <NA>  E-5            57989      11021     69010    10937       6576\r\n 6 <NA>  E-6            19125       4654     23779    10369       4962\r\n 7 <NA>  E-7             5446       1913      7359     6530       2585\r\n 8 <NA>  E-8             1009        438      1447     1786        513\r\n 9 <NA>  E-9              381        202       583      579        144\r\n10 <NA>  TOTAL ENLI~   412074      69733    481807    45976      21759\r\n# ... with 20 more rows, and 10 more variables: Total...8 <dbl>,\r\n#   Male...9 <dbl>, Female...10 <dbl>, Total...11 <dbl>,\r\n#   Male...12 <dbl>, Female...13 <dbl>, Total...14 <dbl>,\r\n#   Male...15 <dbl>, Female...16 <dbl>, Total...17 <dbl>\r\n\r\nInterpreting the Variables\r\nThe data itself categorizes all active duty personnel according to their pay grade and current marital status. Marital status is defined as either single without children, single with children, joint service marriage, or civilian marriage with an additional category representing the summed total between all of them in that specific pay grade.\r\nThere are also 3 sub-categories included in each of the previously mentioned categories (except the grand totals column) further breaking down the data according to gender (Male & Female) and the 3rd being the total between both.\r\nI’ve included code below that renames all the respective columns to something a bit more legible with those ending in; WO representing active duty personnel that are single without children, W representing those that are single with children, J representing those in a joint service marriage, C representing those a part of a civilian marriage and the final column representing the grand total.\r\n\r\n\r\nMarital_Status <- rename(Marital_Status, Male_WO = Male...3, Fem_WO = Female...4, Total_WO = Total...5, Male_W = Male...6, Fem_W = Female...7, Total_W = Total...8, Male_J = Male...9, Fem_J = Female...10, Total_J = Total...11, Male_C = Male...12, Fem_C = Female...13, Total_C = Total...14, Male_Total = Male...15, Fem_Total = Female...16, Grand_Total = Total...17)\r\n\r\n#Checking that all categories were renamed correctly\r\nhead(Marital_Status) %>%\r\n  select(\"Pay Grade\": \"Grand_Total\")\r\n\r\n\r\n# A tibble: 6 x 16\r\n  `Pay Grade` Male_WO Fem_WO Total_WO Male_W Fem_W Total_W Male_J\r\n  <chr>         <dbl>  <dbl>    <dbl>  <dbl> <dbl>   <dbl>  <dbl>\r\n1 E-1           31229   5717    36946    563   122     685    139\r\n2 E-2           53094   8388    61482   1457   275    1732    438\r\n3 E-3          131091  21019   152110   4264  1920    6184   3579\r\n4 E-4          112710  16381   129091   9491  4662   14153   8661\r\n5 E-5           57989  11021    69010  10937  6576   17513  12459\r\n6 E-6           19125   4654    23779  10369  4962   15331   8474\r\n# ... with 8 more variables: Fem_J <dbl>, Total_J <dbl>,\r\n#   Male_C <dbl>, Fem_C <dbl>, Total_C <dbl>, Male_Total <dbl>,\r\n#   Fem_Total <dbl>, Grand_Total <dbl>\r\n\r\nAll data included in this specific data set would be considered numeric.\r\nData Wrangling\r\nThe data present within the imported set can be interpreted in many ways, but for the sake of this assignment, I’ve chosen to sort them in 2 different ways according to the male gender.\r\nTotal Males According to Pay Grade\r\nTo start I used the code present in the chunk below to sort all columns except for the male totals and the pay grade they belong to.\r\n\r\n\r\nMarital_Status %>%\r\n  select(\"Pay Grade\", \"Male_Total\")\r\n\r\n\r\n# A tibble: 30 x 2\r\n   `Pay Grade`    Male_Total\r\n   <chr>               <dbl>\r\n 1 E-1                 36991\r\n 2 E-2                 67472\r\n 3 E-3                193729\r\n 4 E-4                236418\r\n 5 E-5                212329\r\n 6 E-6                148290\r\n 7 E-7                 87042\r\n 8 E-8                 25297\r\n 9 E-9                  9633\r\n10 TOTAL ENLISTED    1017201\r\n# ... with 20 more rows\r\n\r\nThis clearly shows us the total active duty males categorized by their pay grade. Nothing fancy, the data is sorted according to the order in which the pay grades are originally listed in the respective excel document.\r\nSorting Total Males According to their Pay Grade in Descending Order\r\nTo take it a step further, I’ve included the code below that further sorts the previous data but in descending order. This code omits the “GRAND TOTAL”, “TOTAL ENLISTED”, and “TOTAL OFFICER” rows in order to tidy the data so that only each specific pay grade is shown.\r\n\r\n\r\nMarital_Status %>%\r\n  select(\"Pay Grade\", \"Male_Total\") %>%\r\n  filter(`Pay Grade` != \"GRAND TOTAL\" & `Pay Grade` != \"TOTAL ENLISTED\" & `Pay Grade` != \"TOTAL OFFICER\") %>%\r\n  ungroup() %>%\r\n  arrange(desc(Male_Total))\r\n\r\n\r\n# A tibble: 25 x 2\r\n   `Pay Grade` Male_Total\r\n   <chr>            <dbl>\r\n 1 E-4             236418\r\n 2 E-5             212329\r\n 3 E-3             193729\r\n 4 E-6             148290\r\n 5 E-7              87042\r\n 6 E-2              67472\r\n 7 O-3              57973\r\n 8 O-4              38492\r\n 9 E-1              36991\r\n10 O-5              25341\r\n# ... with 15 more rows\r\n\r\nThe filter() command removes the previously mentioned rows, the ungroup() function breaks up the format of the columns so that they may be sorted in descending order and lastly, the arrange function actually sorts the data in the aforementioned descending order. Here we can clearly see that a majority of enlisted males, regardless of marital status, belong to the E-4 pay grade.\r\nI hope that this submission meets all the required criteria, thank you for reading!\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:49-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomjnfarrell211864086/",
    "title": "Homework 2",
    "description": "Reading in and Wrangling Data",
    "author": [
      {
        "name": "Joseph Farrell",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\nInstall libraries\n\n\nlibrary(tidyverse)\nlibrary(dplyr)\n\n\n\nRead in and name data “australian_marriage_data”\n\n\nlibrary(readr)\naustralian_marriage_data <- read_csv(\"/Users/nelsonfarrell/Downloads/australian_marriage_tidy - australian_marriage_tidy.csv\")\nView(australian_marriage_data)\n\n\n\nCheck the variables and columns of “australian_marriage_data”\n\n\nstr(australian_marriage_data)\n\n\nspec_tbl_df [16 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ territory: chr [1:16] \"New South Wales\" \"New South Wales\" \"Victoria\" \"Victoria\" ...\n $ resp     : chr [1:16] \"yes\" \"no\" \"yes\" \"no\" ...\n $ count    : num [1:16] 2374362 1736838 2145629 1161098 1487060 ...\n $ percent  : num [1:16] 57.8 42.2 64.9 35.1 60.7 39.3 62.5 37.5 63.7 36.3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   territory = col_character(),\n  ..   resp = col_character(),\n  ..   count = col_double(),\n  ..   percent = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n“australian_marriage_data” has 4 variables. The first variable (territory) is the territory of the respondent, it is a character. The second variable (resp) is the response, either “yes” or “no,” it is also a character. The third variable (count) is the total number of responses either “yes” or “no” respectively, it is numeric. The fourth variable (percent) is also numeric, it is the percent of respondents who reported either “yes” or “no.”\nFilter “yes” from “australian_marriage_data”\n\n\nfilter(australian_marriage_data, `resp` == \"yes\")\n\n\n# A tibble: 8 × 4\n  territory                       resp    count percent\n  <chr>                           <chr>   <dbl>   <dbl>\n1 New South Wales                 yes   2374362    57.8\n2 Victoria                        yes   2145629    64.9\n3 Queensland                      yes   1487060    60.7\n4 South Australia                 yes    592528    62.5\n5 Western Australia               yes    801575    63.7\n6 Tasmania                        yes    191948    63.6\n7 Northern Territory(b)           yes     48686    60.6\n8 Australian Capital Territory(c) yes    175459    74  \n\nFilter for “yes” and arrange “count” column in descending order\n\n\nfilter(australian_marriage_data, `resp` == \"yes\") %>%\narrange(desc(count))\n\n\n# A tibble: 8 × 4\n  territory                       resp    count percent\n  <chr>                           <chr>   <dbl>   <dbl>\n1 New South Wales                 yes   2374362    57.8\n2 Victoria                        yes   2145629    64.9\n3 Queensland                      yes   1487060    60.7\n4 Western Australia               yes    801575    63.7\n5 South Australia                 yes    592528    62.5\n6 Tasmania                        yes    191948    63.6\n7 Australian Capital Territory(c) yes    175459    74  \n8 Northern Territory(b)           yes     48686    60.6\n\nFilter for “yes”, remove the “count” column, and arrange “percent” column in descending order\n\n\nfilter(australian_marriage_data, `resp` == \"yes\") %>%\nselect(territory, resp, percent) %>%\narrange(desc(percent))\n\n\n# A tibble: 8 × 3\n  territory                       resp  percent\n  <chr>                           <chr>   <dbl>\n1 Australian Capital Territory(c) yes      74  \n2 Victoria                        yes      64.9\n3 Western Australia               yes      63.7\n4 Tasmania                        yes      63.6\n5 South Australia                 yes      62.5\n6 Queensland                      yes      60.7\n7 Northern Territory(b)           yes      60.6\n8 New South Wales                 yes      57.8\n\nFilter the rows below 60 and above 70 in the “percent” column, arrange in descending order\n\n\nfilter(australian_marriage_data, percent > 60 & percent < 70) %>%\n  arrange(desc(percent))\n\n\n# A tibble: 6 × 4\n  territory             resp    count percent\n  <chr>                 <chr>   <dbl>   <dbl>\n1 Victoria              yes   2145629    64.9\n2 Western Australia     yes    801575    63.7\n3 Tasmania              yes    191948    63.6\n4 South Australia       yes    592528    62.5\n5 Queensland            yes   1487060    60.7\n6 Northern Territory(b) yes     48686    60.6\n\nFilter for “yes”, select “percent” and create a new vector “percent_married”\n\n\npercent_married <- filter(australian_marriage_data, `resp` == \"yes\") %>%\nselect(percent) \n\n\n\nCreate blue boxplot for “percent_married”\n\n\n  boxplot(percent_married, horizontal = TRUE, \n          main = \"Boxplot: Australian Marriage Data: 'yes'\", \n          ylab = \"Territories\", \n          xlab = \"Percent of respondents who said 'yes' to being married\", col = (c(\"blue\")))\n\n\n\n\n\n```{.r .distill-force-highlighting-css}\n\n\n",
    "preview": "posts/httpsrpubscomjnfarrell211864086/distill-preview.png",
    "last_modified": "2022-02-09T18:38:02-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomkkimble864029/",
    "title": "Kimble HW1, Try 2",
    "description": "This is the second try for 601 HW 1",
    "author": [
      {
        "name": "Karen Kimble",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\nThis is a test for DACSS 601\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:56-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomkmuhamma860269/",
    "title": "KMuhammad HW1",
    "description": "Data Science Fundamentals - Homework 1",
    "author": [
      {
        "name": "Kalimah Muhammad",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\nDistill is a publication format for scientific and technical writing, native to the web.\r\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:06-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomlcollazohw1take2/",
    "title": "HW1",
    "description": "Take 2 :)",
    "author": [
      {
        "name": "Laura Collazo",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-09T18:36:55-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomlcollazohw2/",
    "title": "HW2",
    "description": "This assignment shows an example of reading in a dataset, explaining the variables in the dataset and then demonstrating at least 2 basic data-wrangling operations.",
    "author": [
      {
        "name": "Laura Collazo",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\nThe dataset used for this assignment is workshop_masterlist. It holds data on faculty who have participated in training offered by my office, and is being shared here with identifiers removed and permission.\r\nThe variables include:\r\nvariable\r\ndata type\r\nid\r\nchar\r\ncampus\r\nchar\r\nworkshop\r\nchar\r\nworkshop_status_id*\r\nchar\r\nworkshop_date\r\ndate\r\nsemester\r\nchar\r\nworkshop_year\r\nchar\r\n*The variable workshop_status_id was intentionally left as an id in the csv, for practice using mutate to tidy the data.\r\n\r\n\r\n#read in dataset from csv and save as object\r\n\r\nwm_csv <- read_csv(\"workshop_masterlist_2022-02-08.csv\")\r\n\r\n#create tibble\r\n\r\nworkshop_masterlist <- as_tibble(wm_csv)\r\n\r\n#create new column workshop_status \r\n\r\nwm <- workshop_masterlist %>%\r\n mutate(workshop_status = case_when(\r\n    workshop_status_id == 1 ~ \"Pass\",\r\n    workshop_status_id == 2 ~ \"No Pass\",\r\n    workshop_status_id == 3 ~ \"Withdraw\",\r\n    workshop_status_id == 4 ~ \"No Show\",\r\n    workshop_status_id == 5 ~ \"Audit\") )\r\n\r\n#check variable types\r\n\r\nstr(wm)\r\n\r\n\r\ntibble [5,844 x 8] (S3: tbl_df/tbl/data.frame)\r\n $ id                : num [1:5844] 3955 3956 3957 3958 3959 ...\r\n $ campus            : chr [1:5844] \"Brooklyn\" \"Brooklyn\" \"York\" \"Brooklyn\" ...\r\n $ workshop          : chr [1:5844] \"OTE\" \"OTE\" \"OTE\" \"OTE\" ...\r\n $ workshop_status_id: num [1:5844] 1 2 1 1 1 1 1 2 1 4 ...\r\n $ workshop_date     : Date[1:5844], format: \"2020-07-09\" ...\r\n $ semester          : chr [1:5844] \"Summer 2020\" \"Summer 2020\" \"Summer 2020\" \"Summer 2020\" ...\r\n $ workshop_year     : num [1:5844] 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 ...\r\n $ workshop_status   : chr [1:5844] \"Pass\" \"No Pass\" \"Pass\" \"Pass\" ...\r\n\r\n#select desired columns in new order, and change incorrect variable types\r\n\r\nwm_tidy <- wm %>% select (id:workshop, workshop_status, workshop_year) %>%\r\n                  mutate(id = as.character(id),\r\n                         workshop_year = as.character(workshop_year))\r\n\r\n#check variable types\r\n\r\nstr(wm_tidy)\r\n\r\n\r\ntibble [5,844 x 5] (S3: tbl_df/tbl/data.frame)\r\n $ id             : chr [1:5844] \"3955\" \"3956\" \"3957\" \"3958\" ...\r\n $ campus         : chr [1:5844] \"Brooklyn\" \"Brooklyn\" \"York\" \"Brooklyn\" ...\r\n $ workshop       : chr [1:5844] \"OTE\" \"OTE\" \"OTE\" \"OTE\" ...\r\n $ workshop_status: chr [1:5844] \"Pass\" \"No Pass\" \"Pass\" \"Pass\" ...\r\n $ workshop_year  : chr [1:5844] \"2020\" \"2020\" \"2020\" \"2020\" ...\r\n\r\n#filter for all participants who passed, and arrange by campus and then year\r\nwm_tidy %>%\r\n  filter(workshop_status == \"Pass\") %>%\r\n  arrange(campus, workshop_year)\r\n\r\n\r\n# A tibble: 4,740 x 5\r\n   id    campus workshop workshop_status workshop_year\r\n   <chr> <chr>  <chr>    <chr>           <chr>        \r\n 1 239   Baruch PTO      Pass            2011         \r\n 2 364   Baruch PTO      Pass            2011         \r\n 3 430   Baruch PTO      Pass            2011         \r\n 4 636   Baruch PTO      Pass            2011         \r\n 5 684   Baruch PTO      Pass            2011         \r\n 6 864   Baruch PTO      Pass            2011         \r\n 7 959   Baruch PTO      Pass            2011         \r\n 8 1048  Baruch PTO      Pass            2011         \r\n 9 1061  Baruch PTO      Pass            2011         \r\n10 1063  Baruch PTO      Pass            2011         \r\n# ... with 4,730 more rows\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:52-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomlenna717860481/",
    "title": "Test Post - Take 3",
    "description": "Basic Math in R",
    "author": [
      {
        "name": "Lenna",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\nIntro to Calculating Numbers with R\nWe can do basic math using R.\nHere are the operators you’ll need for addition, subtraction, multiplication, and division, respectively: + - * /\nWe’ll start with addition.\nAddition\n\n\n4+4\n\n\n[1] 8\n\n3+5\n\n\n[1] 8\n\nSubtraction\n\n\n7-4\n\n\n[1] 3\n\n2-2\n\n\n[1] 0\n\nMultiplication\n\n\n2*2\n\n\n[1] 4\n\n3*5\n\n\n[1] 15\n\nDivision\n\n\n6/2\n\n\n[1] 3\n\n9/3\n\n\n[1] 3\n\nAnd that, my friends, is the story on doing math (albeit very basic math, with R)!\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:16-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscommderiantothdacss601hw1mdt/",
    "title": "Meredith Derian-Toth Homework 1",
    "description": "This describes MDT's HW1",
    "author": [
      {
        "name": "Meredith Derian-Toth",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:19-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomrahulgdacss601hw2/",
    "title": "HW2",
    "description": "Reading in Data",
    "author": [
      {
        "name": "Rahul Gundeti",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\n\r\n[1] month                  year                  \r\n[3] large_half_dozen       large_dozen           \r\n[5] extra_large_half_dozen extra_large_dozen     \r\n<0 rows> (or 0-length row.names)\r\n        month year large_half_dozen large_dozen\r\n1     January 2013          178.000     267.500\r\n2    February 2013          178.000     267.500\r\n3       March 2013          178.000     267.500\r\n4       April 2013          178.000     267.500\r\n5         May 2013          178.000     267.500\r\n6        June 2013          178.000     267.500\r\n7        July 2013          178.000     267.500\r\n8      August 2013          178.000     267.500\r\n9   September 2013          178.000     267.500\r\n10    October 2013          178.000     267.500\r\n11   November 2013          178.000     267.500\r\n12   December 2013          178.000     267.500\r\n13    January 2012          174.500     267.500\r\n14   February 2012          174.500     267.500\r\n15      March 2012          174.500     267.500\r\n16      April 2012          174.500     267.500\r\n17        May 2012          173.250     267.500\r\n18       June 2012          173.250     267.500\r\n19       July 2012          173.250     267.500\r\n20     August 2012          173.250     267.500\r\n21  September 2012          173.250     267.500\r\n22    October 2012          173.250     267.500\r\n23   November 2012          178.000     267.500\r\n24   December 2012          178.000     267.500\r\n25    January 2011          174.500     267.500\r\n26   February 2011          174.500     267.500\r\n27      March 2011          174.500     267.500\r\n28      April 2011          174.500     267.500\r\n29        May 2011          174.500     267.500\r\n30       June 2011          174.500     270.000\r\n31       July 2011          174.500     270.000\r\n32     August 2011          174.500     270.000\r\n33  September 2011          174.500     270.000\r\n34    October 2011          174.500     270.000\r\n35   November 2011          174.500     270.000\r\n36   December 2011          174.500     270.000\r\n37    January 2010          174.500     271.500\r\n38   February 2010          174.500     271.500\r\n39      March 2010          174.500     268.000\r\n40      April 2010          174.500     268.000\r\n41        May 2010          174.500     268.000\r\n42       June 2010          174.500     268.000\r\n43       July 2010          174.500     268.000\r\n44     August 2010          174.500     268.000\r\n45  September 2010          174.500     268.000\r\n46    October 2010          174.500     267.500\r\n47   November 2010          174.500     267.500\r\n48   December 2010          174.500     267.500\r\n49    January 2009          174.500     277.500\r\n50   February 2009          174.500     277.500\r\n51      March 2009          174.500     277.500\r\n52      April 2009          174.500     277.500\r\n53        May 2009          174.500     277.500\r\n54       June 2009          174.500     277.500\r\n55       July 2009          174.500     277.500\r\n56     August 2009          174.500     271.500\r\n57  September 2009          174.500     271.500\r\n58    October 2009          174.500     271.500\r\n59   November 2009          174.500     271.500\r\n60   December 2009          174.500     271.500\r\n61    January 2008          132.000     237.000\r\n62   February 2008          132.000     237.000\r\n63      March 2008          132.000     237.000\r\n64      April 2008          132.000     237.000\r\n65        May 2008          132.000     237.000\r\n66       June 2008          174.500     277.500\r\n67       July 2008          174.500     277.500\r\n68     August 2008          174.500     277.500\r\n69  September 2008          174.500     277.500\r\n70    October 2008          174.500     277.500\r\n71   November 2008          174.500     277.500\r\n72   December 2008          174.500     277.500\r\n73    January 2007          128.500     233.500\r\n74   February 2007          131.125     236.125\r\n75      March 2007          132.000     237.000\r\n76      April 2007          132.000     237.000\r\n77        May 2007          132.000     237.000\r\n78       June 2007          132.000     237.000\r\n79       July 2007          132.000     237.000\r\n80     August 2007          132.000     237.000\r\n81  September 2007          132.000     237.000\r\n82    October 2007          132.000     237.000\r\n83   November 2007          132.000     237.000\r\n84   December 2007          132.000     237.000\r\n85    January 2006          128.500     233.500\r\n86   February 2006          128.500     233.500\r\n87      March 2006          128.500     233.500\r\n88      April 2006          128.500     233.500\r\n89        May 2006          128.500     233.500\r\n90       June 2006          128.500     233.500\r\n91       July 2006          128.500     233.500\r\n92     August 2006          128.500     233.500\r\n93  September 2006          128.500     233.500\r\n94    October 2006          128.500     233.500\r\n95   November 2006          128.500     233.500\r\n96   December 2006          128.500     233.500\r\n97    January 2005          128.500     233.500\r\n98   February 2005          128.500     233.500\r\n99      March 2005          128.500     233.500\r\n100     April 2005          128.500     233.500\r\n101       May 2005          128.500     233.500\r\n102      June 2005          128.500     233.500\r\n103      July 2005          128.500     233.500\r\n104    August 2005          128.500     233.500\r\n105 September 2005          128.500     233.500\r\n106   October 2005          128.500     233.500\r\n107  November 2005          128.500     233.500\r\n108  December 2005          128.500     233.500\r\n109   January 2004          126.000     230.000\r\n110  February 2004          128.500     226.250\r\n111     March 2004          131.000     225.000\r\n112     April 2004          131.000     225.000\r\n113       May 2004          131.000     225.000\r\n114      June 2004          133.500     231.375\r\n115      July 2004          133.500     233.500\r\n116    August 2004          133.500     233.500\r\n117 September 2004          129.750     233.500\r\n118   October 2004          128.500     233.500\r\n119  November 2004          128.500     233.500\r\n120  December 2004          128.500     233.500\r\n    extra_large_half_dozen extra_large_dozen\r\n1                  188.130           290.000\r\n2                  188.130           290.000\r\n3                  188.130           290.000\r\n4                  188.130           290.000\r\n5                  188.130           290.000\r\n6                  188.130           290.000\r\n7                  188.130           290.000\r\n8                  188.130           290.000\r\n9                  188.130           290.000\r\n10                 188.130           290.000\r\n11                 188.130           290.000\r\n12                 188.130           290.000\r\n13                 185.500           285.500\r\n14                 185.500           288.500\r\n15                 185.500           288.500\r\n16                 185.500           288.500\r\n17                 185.500           288.500\r\n18                 185.500           288.500\r\n19                 185.500           288.500\r\n20                 185.500           288.500\r\n21                 185.500           288.500\r\n22                 185.500           288.500\r\n23                 188.130           290.000\r\n24                 188.130           290.000\r\n25                 185.500           285.500\r\n26                 185.500           285.500\r\n27                 185.500           285.500\r\n28                 185.500           285.500\r\n29                 185.500           285.500\r\n30                 185.500           285.500\r\n31                 185.500           285.500\r\n32                 185.500           285.500\r\n33                 185.500           285.500\r\n34                 185.500           285.500\r\n35                 185.500           285.500\r\n36                 185.500           285.500\r\n37                 185.500           285.500\r\n38                 185.500           285.500\r\n39                 185.500           285.500\r\n40                 185.500           285.500\r\n41                 185.500           285.500\r\n42                 185.500           285.500\r\n43                 185.500           285.500\r\n44                 185.500           285.500\r\n45                 185.500           285.500\r\n46                 185.500           285.500\r\n47                 185.500           285.500\r\n48                 185.500           285.500\r\n49                 185.500           285.500\r\n50                 185.500           285.500\r\n51                 185.500           285.500\r\n52                 185.500           285.500\r\n53                 185.500           285.500\r\n54                 185.500           285.500\r\n55                 185.500           285.500\r\n56                 185.500           285.500\r\n57                 185.500           285.500\r\n58                 185.500           285.500\r\n59                 185.500           285.500\r\n60                 185.500           285.500\r\n61                 139.000           245.000\r\n62                 139.000           245.000\r\n63                 139.000           245.000\r\n64                 139.000           245.000\r\n65                 139.000           245.000\r\n66                 185.500           285.500\r\n67                 185.500           285.500\r\n68                 185.500           285.500\r\n69                 185.500           285.500\r\n70                 185.500           285.500\r\n71                 185.500           285.500\r\n72                 185.500           285.500\r\n73                 135.500           241.500\r\n74                 138.125           244.125\r\n75                 139.000           245.000\r\n76                 139.000           245.000\r\n77                 139.000           245.000\r\n78                 139.000           245.000\r\n79                 139.000           245.000\r\n80                 139.000           245.000\r\n81                 139.000           245.000\r\n82                 139.000           245.000\r\n83                 139.000           245.000\r\n84                 139.000           245.000\r\n85                 135.500           241.000\r\n86                 135.500           241.000\r\n87                 135.500           241.375\r\n88                 135.500           241.500\r\n89                 135.500           241.500\r\n90                 135.500           241.500\r\n91                 135.500           241.500\r\n92                 135.500           241.500\r\n93                 135.500           241.500\r\n94                 135.500           241.500\r\n95                 135.500           241.500\r\n96                 135.500           241.500\r\n97                 135.500           241.000\r\n98                 135.500           241.000\r\n99                 135.500           241.000\r\n100                135.500           241.000\r\n101                135.500           241.000\r\n102                135.500           241.000\r\n103                135.500           241.000\r\n104                135.500           241.000\r\n105                135.500           241.000\r\n106                135.500           241.000\r\n107                135.500           241.000\r\n108                135.500           241.000\r\n109                132.000           230.000\r\n110                134.500           230.000\r\n111                137.000           230.000\r\n112                137.000           234.500\r\n113                137.000           236.000\r\n114                137.000           241.000\r\n115                137.000           241.000\r\n116                137.000           241.000\r\n117                135.875           241.000\r\n118                135.500           241.000\r\n119                135.500           241.000\r\n120                135.500           241.000\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:42-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomry0531862527/",
    "title": "Roy Yoon HW1",
    "description": "DACSS HW1",
    "author": [
      {
        "name": "Roy Yoon",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-09T18:37:25-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomtbartelloni862736/",
    "title": "Australian Survey About Marriage Law Change",
    "description": "This is a brief exploratory analysis regarding the results of a survey of Australians' opinions of changing the Australian marriage law to allow same sex marriage.",
    "author": [
      {
        "name": "Tory Bartelloni",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\r\nIntroduction\r\nThe following page will describe my personal journey of very briefly analyzing a survey conducted by the Australian Bureau of Statistics in the fall of 2017. This survey was done through the postal service, was completely voluntary, and was sent to all registered voters in Australia to gauge the public’s opinion of changing the law to allow same sex couples to marry. The intent of this page is to clearly outline my thought process and coding steps taken to practice reading, wrangling, and operating on a not-so-tidy data set.\r\nReading and Understanding the Avaialble Data\r\nFirst, we will read in the data from the results of the survey.\r\n\r\n\r\nam_survey <- read_xls(\"australian_marriage_law_postal_survey_2017_-_response_final.xls\") \r\nam_survey\r\n\r\n\r\n# A tibble: 23 x 3\r\n   `Australian Bureau of Statistics`                  ...2       ...3 \r\n   <chr>                                              <chr>      <chr>\r\n 1 1800.0 Australian Marriage Law Postal Survey, 2017 <NA>       <NA> \r\n 2 Released on 15 November 2017                       <NA>       <NA> \r\n 3 <NA>                                               <NA>       <NA> \r\n 4 <NA>                                               Contents   <NA> \r\n 5 <NA>                                               Tables     <NA> \r\n 6 <NA>                                               Table 1    Resp~\r\n 7 <NA>                                               Table 2    Resp~\r\n 8 <NA>                                               <NA>       <NA> \r\n 9 <NA>                                               Explanato~ <NA> \r\n10 <NA>                                               <NA>       <NA> \r\n# ... with 13 more rows\r\n\r\nAfter reading and viewing the imported data we notice that the table that was read looks to be a title page for additional pages. There are three referenced links on this page including references to “Table 1” and “Table 2”, which are likely of interest. Now we will read in each of these sheets and review them as well.\r\n\r\n\r\nam_survey_tbl1 <- read_xls(\"australian_marriage_law_postal_survey_2017_-_response_final.xls\", sheet = \"Table 1\")\r\nam_survey_tbl2 <- read_xls(\"australian_marriage_law_postal_survey_2017_-_response_final.xls\", sheet = \"Table 2\")\r\n\r\nam_survey_tbl1\r\n\r\n\r\n# A tibble: 21 x 16\r\n   `Australian Burea~` ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 \r\n   <chr>               <chr> <chr> <chr> <chr> <chr> <chr> <lgl> <chr>\r\n 1 1800.0 Australian ~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 2 Released on 15 Nov~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 3 Table 1 Response b~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 4 <NA>                Resp~ <NA>  <NA>  <NA>  <NA>  <NA>  NA    Elig~\r\n 5 <NA>                Yes   <NA>  No    <NA>  Total <NA>  NA    Resp~\r\n 6 <NA>                no.   %     no.   %     no.   %     NA    no.  \r\n 7 New South Wales     2374~ 57.7~ 1736~ 42.2~ 4111~ 100   NA    4111~\r\n 8 Victoria            2145~ 64.9~ 1161~ 35.1~ 3306~ 100   NA    3306~\r\n 9 Queensland          1487~ 60.7~ 9610~ 39.2~ 2448~ 100   NA    2448~\r\n10 South Australia     5925~ 62.5  3562~ 37.5  9487~ 100   NA    9487~\r\n# ... with 11 more rows, and 7 more variables: ...10 <chr>,\r\n#   ...11 <chr>, ...12 <chr>, ...13 <chr>, ...14 <chr>, ...15 <chr>,\r\n#   ...16 <chr>\r\n\r\nam_survey_tbl2\r\n\r\n\r\n# A tibble: 190 x 16\r\n   `Australian Burea~` ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 \r\n   <chr>               <chr> <chr> <chr> <chr> <chr> <chr> <lgl> <chr>\r\n 1 1800.0 Australian ~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 2 Released on 15 Nov~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 3 Table 2 Response b~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 4 <NA>                Resp~ <NA>  <NA>  <NA>  <NA>  <NA>  NA    Elig~\r\n 5 <NA>                Yes   <NA>  No    <NA>  Total <NA>  NA    Resp~\r\n 6 <NA>                no.   %     no.   %     no.   %     NA    no.  \r\n 7 New South Wales Di~ <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  NA    <NA> \r\n 8 Banks               37736 44.8~ 46343 55.1~ 84079 100   NA    84079\r\n 9 Barton              37153 43.6~ 47984 56.3~ 85137 100   NA    85137\r\n10 Bennelong           42943 49.7~ 43215 50.2~ 86158 100   NA    86158\r\n# ... with 180 more rows, and 7 more variables: ...10 <chr>,\r\n#   ...11 <chr>, ...12 <chr>, ...13 <chr>, ...14 <chr>, ...15 <chr>,\r\n#   ...16 <chr>\r\n\r\nReviewing the table sheets and their associated data we now see that Table 1 is an aggregate of data from Table 2 by State/Territory. From here on we can focus on Table 2 as it has all of the underlying data that we will be interested in.\r\nWrangling and Cleaning the Data\r\nFocusing on Table 2, we see that several of the first rows are used for description, several more rows are used to describe groups of variables, several columns are duplicates or aggregates, and it includes title and sub-total lines for each State/Territory.\r\nTo deal with this we will 1) re-read the data and skip the descriptive rows, 2) select only the columns that we will need, 3) add a State/Territory variable to identify the Divisions, and 4) remove the title and sub-total lines. We will also take this opportunity to assign appropriate names to our variables.\r\n\r\n\r\n# Read in and skip first 7  rows with miscellaneous information\r\nam_survey_final <- read_xls(\"australian_marriage_law_postal_survey_2017_-_response_final.xls\", \r\n                           sheet = \"Table 2\", skip=7)\r\n# Subset to only the columns we're interested in. Will be keeping: Yes answers, No answers,\r\n# Eligible participants with clear responses, without clear responses, and non-responders.\r\nam_survey_final <- am_survey_final[,c(1,2,4,6,11,13)]\r\n\r\n# Add a State_Territory variable\r\nam_survey_final$State_Territory <- NA\r\n\r\n# Assign appropriate values to the State_Territory variable\r\nam_survey_final[1:47,]$State_Territory <- \"New South Wales\"\r\nam_survey_final[51:87,]$State_Territory <- \"Victoria\"\r\nam_survey_final[91:120,]$State_Territory <- \"Queensland\"\r\nam_survey_final[124:134,]$State_Territory <- \"South Australia\"\r\nam_survey_final[138:153,]$State_Territory <- \"Western Australia\"\r\nam_survey_final[157:161,]$State_Territory <- \"Tasmania\"\r\nam_survey_final[165:166,]$State_Territory <- \"Northern Territory\"\r\nam_survey_final[170:171,]$State_Territory <- \"Australian Capital\"\r\n\r\n# Remove all total and title lines\r\nam_survey_final <- am_survey_final %>% filter(!is.na(State_Territory))\r\n\r\n# Add clear column names\r\ncolnames(am_survey_final) <- c(\"Division\",\"Yes\",\"No\",\"Clear Responses\",\"Not Clear Responses\",\"Non-Responders\",\"State_Territory\")\r\n\r\n\r\n\r\nAlright, let’s check it out.\r\n\r\n\r\nstr(am_survey_final)\r\n\r\n\r\ntibble [150 x 7] (S3: tbl_df/tbl/data.frame)\r\n $ Division           : chr [1:150] \"Banks\" \"Barton\" \"Bennelong\" \"Berowra\" ...\r\n $ Yes                : num [1:150] 37736 37153 42943 48471 20406 ...\r\n $ No                 : num [1:150] 46343 47984 43215 40369 57926 ...\r\n $ Clear Responses    : num [1:150] 84079 85137 86158 88840 78332 ...\r\n $ Not Clear Responses: num [1:150] 247 226 244 212 220 202 285 263 229 315 ...\r\n $ Non-Responders     : num [1:150] 20928 24008 19973 16038 25883 ...\r\n $ State_Territory    : chr [1:150] \"New South Wales\" \"New South Wales\" \"New South Wales\" \"New South Wales\" ...\r\n\r\nrmarkdown::paged_table(am_survey_final)\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"Division\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Yes\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"No\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Clear Responses\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Not Clear Responses\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Non-Responders\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"State_Territory\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Banks\",\"2\":\"37736\",\"3\":\"46343\",\"4\":\"84079\",\"5\":\"247\",\"6\":\"20928\",\"7\":\"New South Wales\"},{\"1\":\"Barton\",\"2\":\"37153\",\"3\":\"47984\",\"4\":\"85137\",\"5\":\"226\",\"6\":\"24008\",\"7\":\"New South Wales\"},{\"1\":\"Bennelong\",\"2\":\"42943\",\"3\":\"43215\",\"4\":\"86158\",\"5\":\"244\",\"6\":\"19973\",\"7\":\"New South Wales\"},{\"1\":\"Berowra\",\"2\":\"48471\",\"3\":\"40369\",\"4\":\"88840\",\"5\":\"212\",\"6\":\"16038\",\"7\":\"New South Wales\"},{\"1\":\"Blaxland\",\"2\":\"20406\",\"3\":\"57926\",\"4\":\"78332\",\"5\":\"220\",\"6\":\"25883\",\"7\":\"New South Wales\"},{\"1\":\"Bradfield\",\"2\":\"53681\",\"3\":\"34927\",\"4\":\"88608\",\"5\":\"202\",\"6\":\"17261\",\"7\":\"New South Wales\"},{\"1\":\"Calare\",\"2\":\"54091\",\"3\":\"35779\",\"4\":\"89870\",\"5\":\"285\",\"6\":\"25342\",\"7\":\"New South Wales\"},{\"1\":\"Chifley\",\"2\":\"32871\",\"3\":\"46702\",\"4\":\"79573\",\"5\":\"263\",\"6\":\"28180\",\"7\":\"New South Wales\"},{\"1\":\"Cook\",\"2\":\"47505\",\"3\":\"38804\",\"4\":\"86309\",\"5\":\"229\",\"6\":\"18713\",\"7\":\"New South Wales\"},{\"1\":\"Cowper\",\"2\":\"57493\",\"3\":\"38317\",\"4\":\"95810\",\"5\":\"315\",\"6\":\"25197\",\"7\":\"New South Wales\"},{\"1\":\"Cunningham\",\"2\":\"60906\",\"3\":\"31840\",\"4\":\"92746\",\"5\":\"268\",\"6\":\"20607\",\"7\":\"New South Wales\"},{\"1\":\"Dobell\",\"2\":\"59475\",\"3\":\"30987\",\"4\":\"90462\",\"5\":\"255\",\"6\":\"24275\",\"7\":\"New South Wales\"},{\"1\":\"Eden-Monaro\",\"2\":\"57223\",\"3\":\"30926\",\"4\":\"88149\",\"5\":\"249\",\"6\":\"22139\",\"7\":\"New South Wales\"},{\"1\":\"Farrer\",\"2\":\"48432\",\"3\":\"39297\",\"4\":\"87729\",\"5\":\"277\",\"6\":\"25669\",\"7\":\"New South Wales\"},{\"1\":\"Fowler\",\"2\":\"27847\",\"3\":\"48782\",\"4\":\"76629\",\"5\":\"228\",\"6\":\"29251\",\"7\":\"New South Wales\"},{\"1\":\"Gilmore\",\"2\":\"59322\",\"3\":\"36386\",\"4\":\"95708\",\"5\":\"303\",\"6\":\"23109\",\"7\":\"New South Wales\"},{\"1\":\"Grayndler\",\"2\":\"73208\",\"3\":\"18429\",\"4\":\"91637\",\"5\":\"136\",\"6\":\"16074\",\"7\":\"New South Wales\"},{\"1\":\"Greenway\",\"2\":\"38016\",\"3\":\"43980\",\"4\":\"81996\",\"5\":\"217\",\"6\":\"25253\",\"7\":\"New South Wales\"},{\"1\":\"Hughes\",\"2\":\"51337\",\"3\":\"36558\",\"4\":\"87895\",\"5\":\"185\",\"6\":\"17038\",\"7\":\"New South Wales\"},{\"1\":\"Hume\",\"2\":\"51284\",\"3\":\"36271\",\"4\":\"87555\",\"5\":\"213\",\"6\":\"23457\",\"7\":\"New South Wales\"},{\"1\":\"Hunter\",\"2\":\"59137\",\"3\":\"32723\",\"4\":\"91860\",\"5\":\"251\",\"6\":\"25253\",\"7\":\"New South Wales\"},{\"1\":\"Kingsford Smith\",\"2\":\"56297\",\"3\":\"31510\",\"4\":\"87807\",\"5\":\"225\",\"6\":\"22399\",\"7\":\"New South Wales\"},{\"1\":\"Lindsay\",\"2\":\"49071\",\"3\":\"38295\",\"4\":\"87366\",\"5\":\"234\",\"6\":\"26955\",\"7\":\"New South Wales\"},{\"1\":\"Lyne\",\"2\":\"51416\",\"3\":\"41539\",\"4\":\"92955\",\"5\":\"316\",\"6\":\"21426\",\"7\":\"New South Wales\"},{\"1\":\"Macarthur\",\"2\":\"43323\",\"3\":\"39907\",\"4\":\"83230\",\"5\":\"228\",\"6\":\"27271\",\"7\":\"New South Wales\"},{\"1\":\"Mackellar\",\"2\":\"62350\",\"3\":\"29330\",\"4\":\"91680\",\"5\":\"208\",\"6\":\"17500\",\"7\":\"New South Wales\"},{\"1\":\"Macquarie\",\"2\":\"56180\",\"3\":\"31778\",\"4\":\"87958\",\"5\":\"235\",\"6\":\"18490\",\"7\":\"New South Wales\"},{\"1\":\"McMahon\",\"2\":\"29146\",\"3\":\"53967\",\"4\":\"83113\",\"5\":\"242\",\"6\":\"23721\",\"7\":\"New South Wales\"},{\"1\":\"Mitchell\",\"2\":\"42112\",\"3\":\"43652\",\"4\":\"85764\",\"5\":\"176\",\"6\":\"19436\",\"7\":\"New South Wales\"},{\"1\":\"Newcastle\",\"2\":\"71158\",\"3\":\"23999\",\"4\":\"95157\",\"5\":\"232\",\"6\":\"19970\",\"7\":\"New South Wales\"},{\"1\":\"New England\",\"2\":\"44608\",\"3\":\"40324\",\"4\":\"84932\",\"5\":\"256\",\"6\":\"25581\",\"7\":\"New South Wales\"},{\"1\":\"North Sydney\",\"2\":\"64813\",\"3\":\"25473\",\"4\":\"90286\",\"5\":\"193\",\"6\":\"17538\",\"7\":\"New South Wales\"},{\"1\":\"Page\",\"2\":\"55943\",\"3\":\"37727\",\"4\":\"93670\",\"5\":\"291\",\"6\":\"25645\",\"7\":\"New South Wales\"},{\"1\":\"Parkes\",\"2\":\"41408\",\"3\":\"37108\",\"4\":\"78516\",\"5\":\"241\",\"6\":\"29777\",\"7\":\"New South Wales\"},{\"1\":\"Parramatta\",\"2\":\"29299\",\"3\":\"47038\",\"4\":\"76337\",\"5\":\"197\",\"6\":\"25757\",\"7\":\"New South Wales\"},{\"1\":\"Paterson\",\"2\":\"60915\",\"3\":\"32059\",\"4\":\"92974\",\"5\":\"279\",\"6\":\"24264\",\"7\":\"New South Wales\"},{\"1\":\"Reid\",\"2\":\"43567\",\"3\":\"39061\",\"4\":\"82628\",\"5\":\"203\",\"6\":\"23786\",\"7\":\"New South Wales\"},{\"1\":\"Richmond\",\"2\":\"62591\",\"3\":\"29625\",\"4\":\"92216\",\"5\":\"274\",\"6\":\"22719\",\"7\":\"New South Wales\"},{\"1\":\"Riverina\",\"2\":\"47333\",\"3\":\"39308\",\"4\":\"86641\",\"5\":\"265\",\"6\":\"25632\",\"7\":\"New South Wales\"},{\"1\":\"Robertson\",\"2\":\"58689\",\"3\":\"30614\",\"4\":\"89303\",\"5\":\"231\",\"6\":\"20431\",\"7\":\"New South Wales\"},{\"1\":\"Shortland\",\"2\":\"62455\",\"3\":\"29836\",\"4\":\"92291\",\"5\":\"255\",\"6\":\"19675\",\"7\":\"New South Wales\"},{\"1\":\"Sydney\",\"2\":\"76144\",\"3\":\"14860\",\"4\":\"91004\",\"5\":\"146\",\"6\":\"22093\",\"7\":\"New South Wales\"},{\"1\":\"Warringah\",\"2\":\"64999\",\"3\":\"21660\",\"4\":\"86659\",\"5\":\"172\",\"6\":\"16630\",\"7\":\"New South Wales\"},{\"1\":\"Watson\",\"2\":\"24915\",\"3\":\"57160\",\"4\":\"82075\",\"5\":\"205\",\"6\":\"24634\",\"7\":\"New South Wales\"},{\"1\":\"Wentworth\",\"2\":\"69279\",\"3\":\"16410\",\"4\":\"85689\",\"5\":\"162\",\"6\":\"18121\",\"7\":\"New South Wales\"},{\"1\":\"Werriwa\",\"2\":\"30252\",\"3\":\"53174\",\"4\":\"83426\",\"5\":\"269\",\"6\":\"29282\",\"7\":\"New South Wales\"},{\"1\":\"Whitlam\",\"2\":\"57562\",\"3\":\"34879\",\"4\":\"92441\",\"5\":\"276\",\"6\":\"23064\",\"7\":\"New South Wales\"},{\"1\":\"Aston\",\"2\":\"48455\",\"3\":\"29730\",\"4\":\"78185\",\"5\":\"234\",\"6\":\"17664\",\"7\":\"Victoria\"},{\"1\":\"Ballarat\",\"2\":\"65613\",\"3\":\"27405\",\"4\":\"93018\",\"5\":\"333\",\"6\":\"20923\",\"7\":\"Victoria\"},{\"1\":\"Batman\",\"2\":\"66383\",\"3\":\"26906\",\"4\":\"93289\",\"5\":\"287\",\"6\":\"17901\",\"7\":\"Victoria\"},{\"1\":\"Bendigo\",\"2\":\"63412\",\"3\":\"28852\",\"4\":\"92264\",\"5\":\"333\",\"6\":\"19360\",\"7\":\"Victoria\"},{\"1\":\"Bruce\",\"2\":\"34644\",\"3\":\"39203\",\"4\":\"73847\",\"5\":\"257\",\"6\":\"21261\",\"7\":\"Victoria\"},{\"1\":\"Calwell\",\"2\":\"37839\",\"3\":\"49823\",\"4\":\"87662\",\"5\":\"331\",\"6\":\"23588\",\"7\":\"Victoria\"},{\"1\":\"Casey\",\"2\":\"59959\",\"3\":\"28144\",\"4\":\"88103\",\"5\":\"316\",\"6\":\"16807\",\"7\":\"Victoria\"},{\"1\":\"Chisholm\",\"2\":\"49448\",\"3\":\"30844\",\"4\":\"80292\",\"5\":\"271\",\"6\":\"17188\",\"7\":\"Victoria\"},{\"1\":\"Corangamite\",\"2\":\"69723\",\"3\":\"27708\",\"4\":\"97431\",\"5\":\"326\",\"6\":\"17123\",\"7\":\"Victoria\"},{\"1\":\"Corio\",\"2\":\"62658\",\"3\":\"29865\",\"4\":\"92523\",\"5\":\"359\",\"6\":\"18255\",\"7\":\"Victoria\"},{\"1\":\"Deakin\",\"2\":\"55464\",\"3\":\"28973\",\"4\":\"84437\",\"5\":\"276\",\"6\":\"15389\",\"7\":\"Victoria\"},{\"1\":\"Dunkley\",\"2\":\"62840\",\"3\":\"24471\",\"4\":\"87311\",\"5\":\"285\",\"6\":\"19322\",\"7\":\"Victoria\"},{\"1\":\"Flinders\",\"2\":\"68291\",\"3\":\"29275\",\"4\":\"97566\",\"5\":\"336\",\"6\":\"21407\",\"7\":\"Victoria\"},{\"1\":\"Gellibrand\",\"2\":\"62045\",\"3\":\"29065\",\"4\":\"91110\",\"5\":\"278\",\"6\":\"19771\",\"7\":\"Victoria\"},{\"1\":\"Gippsland\",\"2\":\"51196\",\"3\":\"33910\",\"4\":\"85106\",\"5\":\"338\",\"6\":\"20370\",\"7\":\"Victoria\"},{\"1\":\"Goldstein\",\"2\":\"69726\",\"3\":\"21663\",\"4\":\"91389\",\"5\":\"238\",\"6\":\"14857\",\"7\":\"Victoria\"},{\"1\":\"Gorton\",\"2\":\"49834\",\"3\":\"43587\",\"4\":\"93421\",\"5\":\"347\",\"6\":\"27479\",\"7\":\"Victoria\"},{\"1\":\"Higgins\",\"2\":\"70059\",\"3\":\"19375\",\"4\":\"89434\",\"5\":\"180\",\"6\":\"16615\",\"7\":\"Victoria\"},{\"1\":\"Holt\",\"2\":\"47147\",\"3\":\"45875\",\"4\":\"93022\",\"5\":\"289\",\"6\":\"28260\",\"7\":\"Victoria\"},{\"1\":\"Hotham\",\"2\":\"47986\",\"3\":\"32524\",\"4\":\"80510\",\"5\":\"303\",\"6\":\"19732\",\"7\":\"Victoria\"},{\"1\":\"Indi\",\"2\":\"54563\",\"3\":\"31925\",\"4\":\"86488\",\"5\":\"324\",\"6\":\"18934\",\"7\":\"Victoria\"},{\"1\":\"Isaacs\",\"2\":\"56645\",\"3\":\"30063\",\"4\":\"86708\",\"5\":\"275\",\"6\":\"20692\",\"7\":\"Victoria\"},{\"1\":\"Jagajaga\",\"2\":\"65098\",\"3\":\"23453\",\"4\":\"88551\",\"5\":\"255\",\"6\":\"15363\",\"7\":\"Victoria\"},{\"1\":\"Kooyong\",\"2\":\"63592\",\"3\":\"22729\",\"4\":\"86321\",\"5\":\"231\",\"6\":\"14147\",\"7\":\"Victoria\"},{\"1\":\"Lalor\",\"2\":\"57062\",\"3\":\"43429\",\"4\":\"100491\",\"5\":\"345\",\"6\":\"30127\",\"7\":\"Victoria\"},{\"1\":\"La Trobe\",\"2\":\"61807\",\"3\":\"29826\",\"4\":\"91633\",\"5\":\"268\",\"6\":\"19002\",\"7\":\"Victoria\"},{\"1\":\"Mallee\",\"2\":\"42495\",\"3\":\"35795\",\"4\":\"78290\",\"5\":\"359\",\"6\":\"21207\",\"7\":\"Victoria\"},{\"1\":\"Maribyrnong\",\"2\":\"53208\",\"3\":\"35658\",\"4\":\"88866\",\"5\":\"360\",\"6\":\"23762\",\"7\":\"Victoria\"},{\"1\":\"McEwen\",\"2\":\"73705\",\"3\":\"39007\",\"4\":\"112712\",\"5\":\"377\",\"6\":\"26966\",\"7\":\"Victoria\"},{\"1\":\"McMillan\",\"2\":\"61479\",\"3\":\"36500\",\"4\":\"97979\",\"5\":\"372\",\"6\":\"22403\",\"7\":\"Victoria\"},{\"1\":\"Melbourne\",\"2\":\"81287\",\"3\":\"15839\",\"4\":\"97126\",\"5\":\"182\",\"6\":\"20154\",\"7\":\"Victoria\"},{\"1\":\"Melbourne Ports\",\"2\":\"70589\",\"3\":\"15523\",\"4\":\"86112\",\"5\":\"198\",\"6\":\"18745\",\"7\":\"Victoria\"},{\"1\":\"Menzies\",\"2\":\"47137\",\"3\":\"35626\",\"4\":\"82763\",\"5\":\"258\",\"6\":\"15745\",\"7\":\"Victoria\"},{\"1\":\"Murray\",\"2\":\"48205\",\"3\":\"35452\",\"4\":\"83657\",\"5\":\"357\",\"6\":\"21560\",\"7\":\"Victoria\"},{\"1\":\"Scullin\",\"2\":\"48245\",\"3\":\"42147\",\"4\":\"90392\",\"5\":\"357\",\"6\":\"22817\",\"7\":\"Victoria\"},{\"1\":\"Wannon\",\"2\":\"49340\",\"3\":\"31529\",\"4\":\"80869\",\"5\":\"343\",\"6\":\"18569\",\"7\":\"Victoria\"},{\"1\":\"Wills\",\"2\":\"68450\",\"3\":\"29399\",\"4\":\"97849\",\"5\":\"250\",\"6\":\"20169\",\"7\":\"Victoria\"},{\"1\":\"Blair\",\"2\":\"47194\",\"3\":\"31433\",\"4\":\"78627\",\"5\":\"256\",\"6\":\"23975\",\"7\":\"Queensland\"},{\"1\":\"Bonner\",\"2\":\"52139\",\"3\":\"31891\",\"4\":\"84030\",\"5\":\"209\",\"6\":\"17981\",\"7\":\"Queensland\"},{\"1\":\"Bowman\",\"2\":\"53529\",\"3\":\"32627\",\"4\":\"86156\",\"5\":\"220\",\"6\":\"19691\",\"7\":\"Queensland\"},{\"1\":\"Brisbane\",\"2\":\"72812\",\"3\":\"18762\",\"4\":\"91574\",\"5\":\"159\",\"6\":\"20656\",\"7\":\"Queensland\"},{\"1\":\"Capricornia\",\"2\":\"39917\",\"3\":\"33917\",\"4\":\"73834\",\"5\":\"230\",\"6\":\"24896\",\"7\":\"Queensland\"},{\"1\":\"Dawson\",\"2\":\"42539\",\"3\":\"34599\",\"4\":\"77138\",\"5\":\"205\",\"6\":\"26943\",\"7\":\"Queensland\"},{\"1\":\"Dickson\",\"2\":\"54206\",\"3\":\"28988\",\"4\":\"83194\",\"5\":\"190\",\"6\":\"18527\",\"7\":\"Queensland\"},{\"1\":\"Fadden\",\"2\":\"52154\",\"3\":\"32218\",\"4\":\"84372\",\"5\":\"215\",\"6\":\"26234\",\"7\":\"Queensland\"},{\"1\":\"Fairfax\",\"2\":\"58510\",\"3\":\"32451\",\"4\":\"90961\",\"5\":\"277\",\"6\":\"21335\",\"7\":\"Queensland\"},{\"1\":\"Fisher\",\"2\":\"52023\",\"3\":\"30783\",\"4\":\"82806\",\"5\":\"258\",\"6\":\"19625\",\"7\":\"Queensland\"},{\"1\":\"Flynn\",\"2\":\"39020\",\"3\":\"36783\",\"4\":\"75803\",\"5\":\"262\",\"6\":\"24529\",\"7\":\"Queensland\"},{\"1\":\"Forde\",\"2\":\"46937\",\"3\":\"30585\",\"4\":\"77522\",\"5\":\"231\",\"6\":\"24423\",\"7\":\"Queensland\"},{\"1\":\"Griffith\",\"2\":\"69171\",\"3\":\"21132\",\"4\":\"90303\",\"5\":\"184\",\"6\":\"20133\",\"7\":\"Queensland\"},{\"1\":\"Groom\",\"2\":\"40536\",\"3\":\"41915\",\"4\":\"82451\",\"5\":\"262\",\"6\":\"20717\",\"7\":\"Queensland\"},{\"1\":\"Herbert\",\"2\":\"48110\",\"3\":\"28441\",\"4\":\"76551\",\"5\":\"207\",\"6\":\"29665\",\"7\":\"Queensland\"},{\"1\":\"Hinkler\",\"2\":\"40649\",\"3\":\"39548\",\"4\":\"80197\",\"5\":\"308\",\"6\":\"22425\",\"7\":\"Queensland\"},{\"1\":\"Kennedy\",\"2\":\"33160\",\"3\":\"37784\",\"4\":\"70944\",\"5\":\"263\",\"6\":\"29794\",\"7\":\"Queensland\"},{\"1\":\"Leichhardt\",\"2\":\"47750\",\"3\":\"27606\",\"4\":\"75356\",\"5\":\"239\",\"6\":\"35841\",\"7\":\"Queensland\"},{\"1\":\"Lilley\",\"2\":\"59991\",\"3\":\"28671\",\"4\":\"88662\",\"5\":\"218\",\"6\":\"20249\",\"7\":\"Queensland\"},{\"1\":\"Longman\",\"2\":\"51268\",\"3\":\"33576\",\"4\":\"84844\",\"5\":\"258\",\"6\":\"24250\",\"7\":\"Queensland\"},{\"1\":\"Maranoa\",\"2\":\"35475\",\"3\":\"45308\",\"4\":\"80783\",\"5\":\"352\",\"6\":\"22553\",\"7\":\"Queensland\"},{\"1\":\"McPherson\",\"2\":\"54034\",\"3\":\"28486\",\"4\":\"82520\",\"5\":\"229\",\"6\":\"23214\",\"7\":\"Queensland\"},{\"1\":\"Moncrieff\",\"2\":\"50566\",\"3\":\"28717\",\"4\":\"79283\",\"5\":\"214\",\"6\":\"25232\",\"7\":\"Queensland\"},{\"1\":\"Moreton\",\"2\":\"47418\",\"3\":\"30413\",\"4\":\"77831\",\"5\":\"220\",\"6\":\"20020\",\"7\":\"Queensland\"},{\"1\":\"Oxley\",\"2\":\"44655\",\"3\":\"29365\",\"4\":\"74020\",\"5\":\"224\",\"6\":\"23348\",\"7\":\"Queensland\"},{\"1\":\"Petrie\",\"2\":\"53144\",\"3\":\"33067\",\"4\":\"86211\",\"5\":\"200\",\"6\":\"23323\",\"7\":\"Queensland\"},{\"1\":\"Rankin\",\"2\":\"41570\",\"3\":\"34621\",\"4\":\"76191\",\"5\":\"237\",\"6\":\"26119\",\"7\":\"Queensland\"},{\"1\":\"Ryan\",\"2\":\"64967\",\"3\":\"24451\",\"4\":\"89418\",\"5\":\"162\",\"6\":\"16223\",\"7\":\"Queensland\"},{\"1\":\"Wide Bay\",\"2\":\"46507\",\"3\":\"37065\",\"4\":\"83572\",\"5\":\"319\",\"6\":\"21645\",\"7\":\"Queensland\"},{\"1\":\"Wright\",\"2\":\"47109\",\"3\":\"35812\",\"4\":\"82921\",\"5\":\"280\",\"6\":\"22144\",\"7\":\"Queensland\"},{\"1\":\"Adelaide\",\"2\":\"62769\",\"3\":\"26771\",\"4\":\"89540\",\"5\":\"217\",\"6\":\"20477\",\"7\":\"South Australia\"},{\"1\":\"Barker\",\"2\":\"42498\",\"3\":\"38827\",\"4\":\"81325\",\"5\":\"243\",\"6\":\"24297\",\"7\":\"South Australia\"},{\"1\":\"Boothby\",\"2\":\"62139\",\"3\":\"28556\",\"4\":\"90695\",\"5\":\"234\",\"6\":\"16919\",\"7\":\"South Australia\"},{\"1\":\"Grey\",\"2\":\"40811\",\"3\":\"35750\",\"4\":\"76561\",\"5\":\"260\",\"6\":\"25327\",\"7\":\"South Australia\"},{\"1\":\"Hindmarsh\",\"2\":\"57947\",\"3\":\"33613\",\"4\":\"91560\",\"5\":\"273\",\"6\":\"20548\",\"7\":\"South Australia\"},{\"1\":\"Kingston\",\"2\":\"58863\",\"3\":\"27567\",\"4\":\"86430\",\"5\":\"252\",\"6\":\"20764\",\"7\":\"South Australia\"},{\"1\":\"Makin\",\"2\":\"51547\",\"3\":\"33743\",\"4\":\"85290\",\"5\":\"242\",\"6\":\"21991\",\"7\":\"South Australia\"},{\"1\":\"Mayo\",\"2\":\"57361\",\"3\":\"31247\",\"4\":\"88608\",\"5\":\"261\",\"6\":\"17239\",\"7\":\"South Australia\"},{\"1\":\"Port Adelaide\",\"2\":\"53649\",\"3\":\"33869\",\"4\":\"87518\",\"5\":\"276\",\"6\":\"27253\",\"7\":\"South Australia\"},{\"1\":\"Sturt\",\"2\":\"52308\",\"3\":\"32655\",\"4\":\"84963\",\"5\":\"252\",\"6\":\"19410\",\"7\":\"South Australia\"},{\"1\":\"Wakefield\",\"2\":\"52636\",\"3\":\"33649\",\"4\":\"86285\",\"5\":\"268\",\"6\":\"27802\",\"7\":\"South Australia\"},{\"1\":\"Brand\",\"2\":\"51953\",\"3\":\"25481\",\"4\":\"77434\",\"5\":\"194\",\"6\":\"24466\",\"7\":\"Western Australia\"},{\"1\":\"Burt\",\"2\":\"44058\",\"3\":\"33275\",\"4\":\"77333\",\"5\":\"169\",\"6\":\"24197\",\"7\":\"Western Australia\"},{\"1\":\"Canning\",\"2\":\"48486\",\"3\":\"32019\",\"4\":\"80505\",\"5\":\"214\",\"6\":\"22157\",\"7\":\"Western Australia\"},{\"1\":\"Cowan\",\"2\":\"44388\",\"3\":\"31075\",\"4\":\"75463\",\"5\":\"184\",\"6\":\"21330\",\"7\":\"Western Australia\"},{\"1\":\"Curtin\",\"2\":\"59638\",\"3\":\"22943\",\"4\":\"82581\",\"5\":\"178\",\"6\":\"15706\",\"7\":\"Western Australia\"},{\"1\":\"Durack\",\"2\":\"39304\",\"3\":\"27128\",\"4\":\"66432\",\"5\":\"194\",\"6\":\"31428\",\"7\":\"Western Australia\"},{\"1\":\"Forrest\",\"2\":\"51612\",\"3\":\"29285\",\"4\":\"80897\",\"5\":\"225\",\"6\":\"21752\",\"7\":\"Western Australia\"},{\"1\":\"Fremantle\",\"2\":\"57541\",\"3\":\"24559\",\"4\":\"82100\",\"5\":\"236\",\"6\":\"19878\",\"7\":\"Western Australia\"},{\"1\":\"Hasluck\",\"2\":\"47880\",\"3\":\"28836\",\"4\":\"76716\",\"5\":\"230\",\"6\":\"19570\",\"7\":\"Western Australia\"},{\"1\":\"Moore\",\"2\":\"56690\",\"3\":\"26690\",\"4\":\"83380\",\"5\":\"195\",\"6\":\"16916\",\"7\":\"Western Australia\"},{\"1\":\"O'Connor\",\"2\":\"43554\",\"3\":\"33987\",\"4\":\"77541\",\"5\":\"234\",\"6\":\"24925\",\"7\":\"Western Australia\"},{\"1\":\"Pearce\",\"2\":\"54305\",\"3\":\"30699\",\"4\":\"85004\",\"5\":\"209\",\"6\":\"26401\",\"7\":\"Western Australia\"},{\"1\":\"Perth\",\"2\":\"57510\",\"3\":\"22967\",\"4\":\"80477\",\"5\":\"177\",\"6\":\"19479\",\"7\":\"Western Australia\"},{\"1\":\"Stirling\",\"2\":\"47225\",\"3\":\"30060\",\"4\":\"77285\",\"5\":\"190\",\"6\":\"21345\",\"7\":\"Western Australia\"},{\"1\":\"Swan\",\"2\":\"49093\",\"3\":\"26830\",\"4\":\"75923\",\"5\":\"185\",\"6\":\"21857\",\"7\":\"Western Australia\"},{\"1\":\"Tangney\",\"2\":\"48338\",\"3\":\"30090\",\"4\":\"78428\",\"5\":\"174\",\"6\":\"14926\",\"7\":\"Western Australia\"},{\"1\":\"Bass\",\"2\":\"36249\",\"3\":\"22510\",\"4\":\"58759\",\"5\":\"145\",\"6\":\"15487\",\"7\":\"Tasmania\"},{\"1\":\"Braddon\",\"2\":\"30054\",\"3\":\"25573\",\"4\":\"55627\",\"5\":\"154\",\"6\":\"17632\",\"7\":\"Tasmania\"},{\"1\":\"Denison\",\"2\":\"45005\",\"3\":\"15992\",\"4\":\"60997\",\"5\":\"167\",\"6\":\"13092\",\"7\":\"Tasmania\"},{\"1\":\"Franklin\",\"2\":\"44746\",\"3\":\"20322\",\"4\":\"65068\",\"5\":\"163\",\"6\":\"13605\",\"7\":\"Tasmania\"},{\"1\":\"Lyons\",\"2\":\"35894\",\"3\":\"25258\",\"4\":\"61152\",\"5\":\"176\",\"6\":\"17204\",\"7\":\"Tasmania\"},{\"1\":\"Lingiari(c)\",\"2\":\"19026\",\"3\":\"15898\",\"4\":\"34924\",\"5\":\"106\",\"6\":\"34854\",\"7\":\"Northern Territory\"},{\"1\":\"Solomon\",\"2\":\"29660\",\"3\":\"15792\",\"4\":\"45452\",\"5\":\"123\",\"6\":\"22642\",\"7\":\"Northern Territory\"},{\"1\":\"Canberra(d)\",\"2\":\"89590\",\"3\":\"31361\",\"4\":\"120951\",\"5\":\"281\",\"6\":\"24399\",\"7\":\"Australian Capital\"},{\"1\":\"Fenner(e)\",\"2\":\"85869\",\"3\":\"30159\",\"4\":\"116028\",\"5\":\"253\",\"6\":\"26196\",\"7\":\"Australian Capital\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nYay! We have a decent data set to work with!\r\nFinalized Variable Definitions\r\nBelow is a list of variable definitions to better understand what variables we have decided to take.\r\nDivision: This is an identifier of what State/Territory Division the other variables are referencing.\r\nYes: This is a count of how many responses from the Division were clearly “Yes”.\r\nNo: This is a count of how many responses from the Division were clearly “No”.\r\nClear Responses: This is a total count of how many responses were clear and used.\r\nNot Clear Responses: This is a total count of how many responses were received, but not clear and therefore not used.\r\nNon-Responders: This is s count of how many eligible persons did not respond to the survey.\r\nState_Territory: This is an identifier of the Federal State/Territory that the other variables are referencing.\r\nExplore the Data\r\nNow we will perform some operations on the data to explore it.\r\n\r\n\r\nam_survey_NSW <- am_survey_final %>% filter(State_Territory == \"New South Wales\") %>%\r\n  arrange(-Yes)\r\n\r\nrmarkdown::paged_table(am_survey_NSW)\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"Division\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Yes\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"No\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Clear Responses\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Not Clear Responses\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Non-Responders\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"State_Territory\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Sydney\",\"2\":\"76144\",\"3\":\"14860\",\"4\":\"91004\",\"5\":\"146\",\"6\":\"22093\",\"7\":\"New South Wales\"},{\"1\":\"Grayndler\",\"2\":\"73208\",\"3\":\"18429\",\"4\":\"91637\",\"5\":\"136\",\"6\":\"16074\",\"7\":\"New South Wales\"},{\"1\":\"Newcastle\",\"2\":\"71158\",\"3\":\"23999\",\"4\":\"95157\",\"5\":\"232\",\"6\":\"19970\",\"7\":\"New South Wales\"},{\"1\":\"Wentworth\",\"2\":\"69279\",\"3\":\"16410\",\"4\":\"85689\",\"5\":\"162\",\"6\":\"18121\",\"7\":\"New South Wales\"},{\"1\":\"Warringah\",\"2\":\"64999\",\"3\":\"21660\",\"4\":\"86659\",\"5\":\"172\",\"6\":\"16630\",\"7\":\"New South Wales\"},{\"1\":\"North Sydney\",\"2\":\"64813\",\"3\":\"25473\",\"4\":\"90286\",\"5\":\"193\",\"6\":\"17538\",\"7\":\"New South Wales\"},{\"1\":\"Richmond\",\"2\":\"62591\",\"3\":\"29625\",\"4\":\"92216\",\"5\":\"274\",\"6\":\"22719\",\"7\":\"New South Wales\"},{\"1\":\"Shortland\",\"2\":\"62455\",\"3\":\"29836\",\"4\":\"92291\",\"5\":\"255\",\"6\":\"19675\",\"7\":\"New South Wales\"},{\"1\":\"Mackellar\",\"2\":\"62350\",\"3\":\"29330\",\"4\":\"91680\",\"5\":\"208\",\"6\":\"17500\",\"7\":\"New South Wales\"},{\"1\":\"Paterson\",\"2\":\"60915\",\"3\":\"32059\",\"4\":\"92974\",\"5\":\"279\",\"6\":\"24264\",\"7\":\"New South Wales\"},{\"1\":\"Cunningham\",\"2\":\"60906\",\"3\":\"31840\",\"4\":\"92746\",\"5\":\"268\",\"6\":\"20607\",\"7\":\"New South Wales\"},{\"1\":\"Dobell\",\"2\":\"59475\",\"3\":\"30987\",\"4\":\"90462\",\"5\":\"255\",\"6\":\"24275\",\"7\":\"New South Wales\"},{\"1\":\"Gilmore\",\"2\":\"59322\",\"3\":\"36386\",\"4\":\"95708\",\"5\":\"303\",\"6\":\"23109\",\"7\":\"New South Wales\"},{\"1\":\"Hunter\",\"2\":\"59137\",\"3\":\"32723\",\"4\":\"91860\",\"5\":\"251\",\"6\":\"25253\",\"7\":\"New South Wales\"},{\"1\":\"Robertson\",\"2\":\"58689\",\"3\":\"30614\",\"4\":\"89303\",\"5\":\"231\",\"6\":\"20431\",\"7\":\"New South Wales\"},{\"1\":\"Whitlam\",\"2\":\"57562\",\"3\":\"34879\",\"4\":\"92441\",\"5\":\"276\",\"6\":\"23064\",\"7\":\"New South Wales\"},{\"1\":\"Cowper\",\"2\":\"57493\",\"3\":\"38317\",\"4\":\"95810\",\"5\":\"315\",\"6\":\"25197\",\"7\":\"New South Wales\"},{\"1\":\"Eden-Monaro\",\"2\":\"57223\",\"3\":\"30926\",\"4\":\"88149\",\"5\":\"249\",\"6\":\"22139\",\"7\":\"New South Wales\"},{\"1\":\"Kingsford Smith\",\"2\":\"56297\",\"3\":\"31510\",\"4\":\"87807\",\"5\":\"225\",\"6\":\"22399\",\"7\":\"New South Wales\"},{\"1\":\"Macquarie\",\"2\":\"56180\",\"3\":\"31778\",\"4\":\"87958\",\"5\":\"235\",\"6\":\"18490\",\"7\":\"New South Wales\"},{\"1\":\"Page\",\"2\":\"55943\",\"3\":\"37727\",\"4\":\"93670\",\"5\":\"291\",\"6\":\"25645\",\"7\":\"New South Wales\"},{\"1\":\"Calare\",\"2\":\"54091\",\"3\":\"35779\",\"4\":\"89870\",\"5\":\"285\",\"6\":\"25342\",\"7\":\"New South Wales\"},{\"1\":\"Bradfield\",\"2\":\"53681\",\"3\":\"34927\",\"4\":\"88608\",\"5\":\"202\",\"6\":\"17261\",\"7\":\"New South Wales\"},{\"1\":\"Lyne\",\"2\":\"51416\",\"3\":\"41539\",\"4\":\"92955\",\"5\":\"316\",\"6\":\"21426\",\"7\":\"New South Wales\"},{\"1\":\"Hughes\",\"2\":\"51337\",\"3\":\"36558\",\"4\":\"87895\",\"5\":\"185\",\"6\":\"17038\",\"7\":\"New South Wales\"},{\"1\":\"Hume\",\"2\":\"51284\",\"3\":\"36271\",\"4\":\"87555\",\"5\":\"213\",\"6\":\"23457\",\"7\":\"New South Wales\"},{\"1\":\"Lindsay\",\"2\":\"49071\",\"3\":\"38295\",\"4\":\"87366\",\"5\":\"234\",\"6\":\"26955\",\"7\":\"New South Wales\"},{\"1\":\"Berowra\",\"2\":\"48471\",\"3\":\"40369\",\"4\":\"88840\",\"5\":\"212\",\"6\":\"16038\",\"7\":\"New South Wales\"},{\"1\":\"Farrer\",\"2\":\"48432\",\"3\":\"39297\",\"4\":\"87729\",\"5\":\"277\",\"6\":\"25669\",\"7\":\"New South Wales\"},{\"1\":\"Cook\",\"2\":\"47505\",\"3\":\"38804\",\"4\":\"86309\",\"5\":\"229\",\"6\":\"18713\",\"7\":\"New South Wales\"},{\"1\":\"Riverina\",\"2\":\"47333\",\"3\":\"39308\",\"4\":\"86641\",\"5\":\"265\",\"6\":\"25632\",\"7\":\"New South Wales\"},{\"1\":\"New England\",\"2\":\"44608\",\"3\":\"40324\",\"4\":\"84932\",\"5\":\"256\",\"6\":\"25581\",\"7\":\"New South Wales\"},{\"1\":\"Reid\",\"2\":\"43567\",\"3\":\"39061\",\"4\":\"82628\",\"5\":\"203\",\"6\":\"23786\",\"7\":\"New South Wales\"},{\"1\":\"Macarthur\",\"2\":\"43323\",\"3\":\"39907\",\"4\":\"83230\",\"5\":\"228\",\"6\":\"27271\",\"7\":\"New South Wales\"},{\"1\":\"Bennelong\",\"2\":\"42943\",\"3\":\"43215\",\"4\":\"86158\",\"5\":\"244\",\"6\":\"19973\",\"7\":\"New South Wales\"},{\"1\":\"Mitchell\",\"2\":\"42112\",\"3\":\"43652\",\"4\":\"85764\",\"5\":\"176\",\"6\":\"19436\",\"7\":\"New South Wales\"},{\"1\":\"Parkes\",\"2\":\"41408\",\"3\":\"37108\",\"4\":\"78516\",\"5\":\"241\",\"6\":\"29777\",\"7\":\"New South Wales\"},{\"1\":\"Greenway\",\"2\":\"38016\",\"3\":\"43980\",\"4\":\"81996\",\"5\":\"217\",\"6\":\"25253\",\"7\":\"New South Wales\"},{\"1\":\"Banks\",\"2\":\"37736\",\"3\":\"46343\",\"4\":\"84079\",\"5\":\"247\",\"6\":\"20928\",\"7\":\"New South Wales\"},{\"1\":\"Barton\",\"2\":\"37153\",\"3\":\"47984\",\"4\":\"85137\",\"5\":\"226\",\"6\":\"24008\",\"7\":\"New South Wales\"},{\"1\":\"Chifley\",\"2\":\"32871\",\"3\":\"46702\",\"4\":\"79573\",\"5\":\"263\",\"6\":\"28180\",\"7\":\"New South Wales\"},{\"1\":\"Werriwa\",\"2\":\"30252\",\"3\":\"53174\",\"4\":\"83426\",\"5\":\"269\",\"6\":\"29282\",\"7\":\"New South Wales\"},{\"1\":\"Parramatta\",\"2\":\"29299\",\"3\":\"47038\",\"4\":\"76337\",\"5\":\"197\",\"6\":\"25757\",\"7\":\"New South Wales\"},{\"1\":\"McMahon\",\"2\":\"29146\",\"3\":\"53967\",\"4\":\"83113\",\"5\":\"242\",\"6\":\"23721\",\"7\":\"New South Wales\"},{\"1\":\"Fowler\",\"2\":\"27847\",\"3\":\"48782\",\"4\":\"76629\",\"5\":\"228\",\"6\":\"29251\",\"7\":\"New South Wales\"},{\"1\":\"Watson\",\"2\":\"24915\",\"3\":\"57160\",\"4\":\"82075\",\"5\":\"205\",\"6\":\"24634\",\"7\":\"New South Wales\"},{\"1\":\"Blaxland\",\"2\":\"20406\",\"3\":\"57926\",\"4\":\"78332\",\"5\":\"220\",\"6\":\"25883\",\"7\":\"New South Wales\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nAnd, for fun, let’s plot some of the results. I am interested to see how the population responded in terms of proportion of YES and NO responses and how that distribution may be impacted by the State/Territory of the populations.\r\nSo what we will do is calculate the proportions of responses, plot the distribution, and highlight the results by State/Territory to see what, if any, patterns emerge.\r\n\r\n\r\nam_survey_ST_grouped <- am_survey_final %>% group_by(State_Territory,Division) %>%\r\n  summarise(Total_Responses = sum(`Clear Responses`,`Not Clear Responses`),\r\n            Married_Perc = sum(Yes)/sum((Yes+No))) %>%\r\n  arrange(-Total_Responses)\r\nrmarkdown::paged_table(am_survey_ST_grouped)\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"State_Territory\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Division\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Total_Responses\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Married_Perc\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Australian Capital\",\"2\":\"Canberra(d)\",\"3\":\"121232\",\"4\":\"0.7407132\"},{\"1\":\"Australian Capital\",\"2\":\"Fenner(e)\",\"3\":\"116281\",\"4\":\"0.7400714\"},{\"1\":\"Victoria\",\"2\":\"McEwen\",\"3\":\"113089\",\"4\":\"0.6539233\"},{\"1\":\"Victoria\",\"2\":\"Lalor\",\"3\":\"100836\",\"4\":\"0.5678319\"},{\"1\":\"Victoria\",\"2\":\"McMillan\",\"3\":\"98351\",\"4\":\"0.6274712\"},{\"1\":\"Victoria\",\"2\":\"Wills\",\"3\":\"98099\",\"4\":\"0.6995473\"},{\"1\":\"Victoria\",\"2\":\"Flinders\",\"3\":\"97902\",\"4\":\"0.6999467\"},{\"1\":\"Victoria\",\"2\":\"Corangamite\",\"3\":\"97757\",\"4\":\"0.7156141\"},{\"1\":\"Victoria\",\"2\":\"Melbourne\",\"3\":\"97308\",\"4\":\"0.8369232\"},{\"1\":\"New South Wales\",\"2\":\"Cowper\",\"3\":\"96125\",\"4\":\"0.6000731\"},{\"1\":\"New South Wales\",\"2\":\"Gilmore\",\"3\":\"96011\",\"4\":\"0.6198228\"},{\"1\":\"New South Wales\",\"2\":\"Newcastle\",\"3\":\"95389\",\"4\":\"0.7477957\"},{\"1\":\"New South Wales\",\"2\":\"Page\",\"3\":\"93961\",\"4\":\"0.5972350\"},{\"1\":\"Victoria\",\"2\":\"Gorton\",\"3\":\"93768\",\"4\":\"0.5334347\"},{\"1\":\"Victoria\",\"2\":\"Batman\",\"3\":\"93576\",\"4\":\"0.7115844\"},{\"1\":\"Victoria\",\"2\":\"Ballarat\",\"3\":\"93351\",\"4\":\"0.7053796\"},{\"1\":\"Victoria\",\"2\":\"Holt\",\"3\":\"93311\",\"4\":\"0.5068371\"},{\"1\":\"New South Wales\",\"2\":\"Lyne\",\"3\":\"93271\",\"4\":\"0.5531279\"},{\"1\":\"New South Wales\",\"2\":\"Paterson\",\"3\":\"93253\",\"4\":\"0.6551832\"},{\"1\":\"New South Wales\",\"2\":\"Cunningham\",\"3\":\"93014\",\"4\":\"0.6566968\"},{\"1\":\"Victoria\",\"2\":\"Corio\",\"3\":\"92882\",\"4\":\"0.6772154\"},{\"1\":\"New South Wales\",\"2\":\"Whitlam\",\"3\":\"92717\",\"4\":\"0.6226891\"},{\"1\":\"Victoria\",\"2\":\"Bendigo\",\"3\":\"92597\",\"4\":\"0.6872886\"},{\"1\":\"New South Wales\",\"2\":\"Shortland\",\"3\":\"92546\",\"4\":\"0.6767182\"},{\"1\":\"New South Wales\",\"2\":\"Richmond\",\"3\":\"92490\",\"4\":\"0.6787434\"},{\"1\":\"New South Wales\",\"2\":\"Hunter\",\"3\":\"92111\",\"4\":\"0.6437731\"},{\"1\":\"Victoria\",\"2\":\"La Trobe\",\"3\":\"91901\",\"4\":\"0.6745059\"},{\"1\":\"New South Wales\",\"2\":\"Mackellar\",\"3\":\"91888\",\"4\":\"0.6800829\"},{\"1\":\"South Australia\",\"2\":\"Hindmarsh\",\"3\":\"91833\",\"4\":\"0.6328855\"},{\"1\":\"New South Wales\",\"2\":\"Grayndler\",\"3\":\"91773\",\"4\":\"0.7988913\"},{\"1\":\"Queensland\",\"2\":\"Brisbane\",\"3\":\"91733\",\"4\":\"0.7951165\"},{\"1\":\"Victoria\",\"2\":\"Goldstein\",\"3\":\"91627\",\"4\":\"0.7629583\"},{\"1\":\"Victoria\",\"2\":\"Gellibrand\",\"3\":\"91388\",\"4\":\"0.6809900\"},{\"1\":\"Queensland\",\"2\":\"Fairfax\",\"3\":\"91238\",\"4\":\"0.6432427\"},{\"1\":\"New South Wales\",\"2\":\"Sydney\",\"3\":\"91150\",\"4\":\"0.8367105\"},{\"1\":\"South Australia\",\"2\":\"Boothby\",\"3\":\"90929\",\"4\":\"0.6851425\"},{\"1\":\"Victoria\",\"2\":\"Scullin\",\"3\":\"90749\",\"4\":\"0.5337309\"},{\"1\":\"New South Wales\",\"2\":\"Dobell\",\"3\":\"90717\",\"4\":\"0.6574584\"},{\"1\":\"Queensland\",\"2\":\"Griffith\",\"3\":\"90487\",\"4\":\"0.7659878\"},{\"1\":\"New South Wales\",\"2\":\"North Sydney\",\"3\":\"90479\",\"4\":\"0.7178632\"},{\"1\":\"New South Wales\",\"2\":\"Calare\",\"3\":\"90155\",\"4\":\"0.6018805\"},{\"1\":\"South Australia\",\"2\":\"Adelaide\",\"3\":\"89757\",\"4\":\"0.7010163\"},{\"1\":\"Victoria\",\"2\":\"Higgins\",\"3\":\"89614\",\"4\":\"0.7833598\"},{\"1\":\"Queensland\",\"2\":\"Ryan\",\"3\":\"89580\",\"4\":\"0.7265539\"},{\"1\":\"New South Wales\",\"2\":\"Robertson\",\"3\":\"89534\",\"4\":\"0.6571896\"},{\"1\":\"Victoria\",\"2\":\"Maribyrnong\",\"3\":\"89226\",\"4\":\"0.5987442\"},{\"1\":\"New South Wales\",\"2\":\"Berowra\",\"3\":\"89052\",\"4\":\"0.5455988\"},{\"1\":\"Queensland\",\"2\":\"Lilley\",\"3\":\"88880\",\"4\":\"0.6766258\"},{\"1\":\"South Australia\",\"2\":\"Mayo\",\"3\":\"88869\",\"4\":\"0.6473569\"},{\"1\":\"New South Wales\",\"2\":\"Bradfield\",\"3\":\"88810\",\"4\":\"0.6058257\"},{\"1\":\"Victoria\",\"2\":\"Jagajaga\",\"3\":\"88806\",\"4\":\"0.7351470\"},{\"1\":\"Victoria\",\"2\":\"Casey\",\"3\":\"88419\",\"4\":\"0.6805557\"},{\"1\":\"New South Wales\",\"2\":\"Eden-Monaro\",\"3\":\"88398\",\"4\":\"0.6491622\"},{\"1\":\"New South Wales\",\"2\":\"Macquarie\",\"3\":\"88193\",\"4\":\"0.6387139\"},{\"1\":\"New South Wales\",\"2\":\"Hughes\",\"3\":\"88080\",\"4\":\"0.5840719\"},{\"1\":\"New South Wales\",\"2\":\"Kingsford Smith\",\"3\":\"88032\",\"4\":\"0.6411448\"},{\"1\":\"New South Wales\",\"2\":\"Farrer\",\"3\":\"88006\",\"4\":\"0.5520637\"},{\"1\":\"Victoria\",\"2\":\"Calwell\",\"3\":\"87993\",\"4\":\"0.4316466\"},{\"1\":\"South Australia\",\"2\":\"Port Adelaide\",\"3\":\"87794\",\"4\":\"0.6130053\"},{\"1\":\"New South Wales\",\"2\":\"Hume\",\"3\":\"87768\",\"4\":\"0.5857347\"},{\"1\":\"New South Wales\",\"2\":\"Lindsay\",\"3\":\"87600\",\"4\":\"0.5616716\"},{\"1\":\"Victoria\",\"2\":\"Dunkley\",\"3\":\"87596\",\"4\":\"0.7197260\"},{\"1\":\"Victoria\",\"2\":\"Isaacs\",\"3\":\"86983\",\"4\":\"0.6532846\"},{\"1\":\"New South Wales\",\"2\":\"Riverina\",\"3\":\"86906\",\"4\":\"0.5463118\"},{\"1\":\"New South Wales\",\"2\":\"Warringah\",\"3\":\"86831\",\"4\":\"0.7500548\"},{\"1\":\"Victoria\",\"2\":\"Indi\",\"3\":\"86812\",\"4\":\"0.6308736\"},{\"1\":\"South Australia\",\"2\":\"Kingston\",\"3\":\"86682\",\"4\":\"0.6810482\"},{\"1\":\"South Australia\",\"2\":\"Wakefield\",\"3\":\"86553\",\"4\":\"0.6100249\"},{\"1\":\"Victoria\",\"2\":\"Kooyong\",\"3\":\"86552\",\"4\":\"0.7366921\"},{\"1\":\"New South Wales\",\"2\":\"Cook\",\"3\":\"86538\",\"4\":\"0.5504061\"},{\"1\":\"Queensland\",\"2\":\"Petrie\",\"3\":\"86411\",\"4\":\"0.6164411\"},{\"1\":\"New South Wales\",\"2\":\"Bennelong\",\"3\":\"86402\",\"4\":\"0.4984215\"},{\"1\":\"Queensland\",\"2\":\"Bowman\",\"3\":\"86376\",\"4\":\"0.6213032\"},{\"1\":\"Victoria\",\"2\":\"Melbourne Ports\",\"3\":\"86310\",\"4\":\"0.8197348\"},{\"1\":\"New South Wales\",\"2\":\"Mitchell\",\"3\":\"85940\",\"4\":\"0.4910219\"},{\"1\":\"New South Wales\",\"2\":\"Wentworth\",\"3\":\"85851\",\"4\":\"0.8084935\"},{\"1\":\"South Australia\",\"2\":\"Makin\",\"3\":\"85532\",\"4\":\"0.6043733\"},{\"1\":\"Victoria\",\"2\":\"Gippsland\",\"3\":\"85444\",\"4\":\"0.6015557\"},{\"1\":\"New South Wales\",\"2\":\"Barton\",\"3\":\"85363\",\"4\":\"0.4363908\"},{\"1\":\"South Australia\",\"2\":\"Sturt\",\"3\":\"85215\",\"4\":\"0.6156562\"},{\"1\":\"Western Australia\",\"2\":\"Pearce\",\"3\":\"85213\",\"4\":\"0.6388523\"},{\"1\":\"New South Wales\",\"2\":\"New England\",\"3\":\"85188\",\"4\":\"0.5252202\"},{\"1\":\"Queensland\",\"2\":\"Longman\",\"3\":\"85102\",\"4\":\"0.6042619\"},{\"1\":\"Victoria\",\"2\":\"Deakin\",\"3\":\"84713\",\"4\":\"0.6568684\"},{\"1\":\"Queensland\",\"2\":\"Fadden\",\"3\":\"84587\",\"4\":\"0.6181435\"},{\"1\":\"New South Wales\",\"2\":\"Banks\",\"3\":\"84326\",\"4\":\"0.4488160\"},{\"1\":\"Queensland\",\"2\":\"Bonner\",\"3\":\"84239\",\"4\":\"0.6204808\"},{\"1\":\"Victoria\",\"2\":\"Murray\",\"3\":\"84014\",\"4\":\"0.5762220\"},{\"1\":\"Queensland\",\"2\":\"Wide Bay\",\"3\":\"83891\",\"4\":\"0.5564902\"},{\"1\":\"New South Wales\",\"2\":\"Werriwa\",\"3\":\"83695\",\"4\":\"0.3626208\"},{\"1\":\"Western Australia\",\"2\":\"Moore\",\"3\":\"83575\",\"4\":\"0.6798993\"},{\"1\":\"New South Wales\",\"2\":\"Macarthur\",\"3\":\"83458\",\"4\":\"0.5205214\"},{\"1\":\"Queensland\",\"2\":\"Dickson\",\"3\":\"83384\",\"4\":\"0.6515614\"},{\"1\":\"New South Wales\",\"2\":\"McMahon\",\"3\":\"83355\",\"4\":\"0.3506792\"},{\"1\":\"Queensland\",\"2\":\"Wright\",\"3\":\"83201\",\"4\":\"0.5681191\"},{\"1\":\"Queensland\",\"2\":\"Fisher\",\"3\":\"83064\",\"4\":\"0.6282516\"},{\"1\":\"Victoria\",\"2\":\"Menzies\",\"3\":\"83021\",\"4\":\"0.5695419\"},{\"1\":\"New South Wales\",\"2\":\"Reid\",\"3\":\"82831\",\"4\":\"0.5272668\"},{\"1\":\"Western Australia\",\"2\":\"Curtin\",\"3\":\"82759\",\"4\":\"0.7221758\"},{\"1\":\"Queensland\",\"2\":\"McPherson\",\"3\":\"82749\",\"4\":\"0.6547988\"},{\"1\":\"Queensland\",\"2\":\"Groom\",\"3\":\"82713\",\"4\":\"0.4916375\"},{\"1\":\"Western Australia\",\"2\":\"Fremantle\",\"3\":\"82336\",\"4\":\"0.7008648\"},{\"1\":\"New South Wales\",\"2\":\"Watson\",\"3\":\"82280\",\"4\":\"0.3035638\"},{\"1\":\"New South Wales\",\"2\":\"Greenway\",\"3\":\"82213\",\"4\":\"0.4636324\"},{\"1\":\"South Australia\",\"2\":\"Barker\",\"3\":\"81568\",\"4\":\"0.5225699\"},{\"1\":\"Victoria\",\"2\":\"Wannon\",\"3\":\"81212\",\"4\":\"0.6101225\"},{\"1\":\"Queensland\",\"2\":\"Maranoa\",\"3\":\"81135\",\"4\":\"0.4391394\"},{\"1\":\"Western Australia\",\"2\":\"Forrest\",\"3\":\"81122\",\"4\":\"0.6379965\"},{\"1\":\"Victoria\",\"2\":\"Hotham\",\"3\":\"80813\",\"4\":\"0.5960253\"},{\"1\":\"Western Australia\",\"2\":\"Canning\",\"3\":\"80719\",\"4\":\"0.6022732\"},{\"1\":\"Western Australia\",\"2\":\"Perth\",\"3\":\"80654\",\"4\":\"0.7146141\"},{\"1\":\"Victoria\",\"2\":\"Chisholm\",\"3\":\"80563\",\"4\":\"0.6158521\"},{\"1\":\"Queensland\",\"2\":\"Hinkler\",\"3\":\"80505\",\"4\":\"0.5068643\"},{\"1\":\"New South Wales\",\"2\":\"Chifley\",\"3\":\"79836\",\"4\":\"0.4130924\"},{\"1\":\"Queensland\",\"2\":\"Moncrieff\",\"3\":\"79497\",\"4\":\"0.6377912\"},{\"1\":\"Queensland\",\"2\":\"Blair\",\"3\":\"78883\",\"4\":\"0.6002264\"},{\"1\":\"New South Wales\",\"2\":\"Parkes\",\"3\":\"78757\",\"4\":\"0.5273830\"},{\"1\":\"Victoria\",\"2\":\"Mallee\",\"3\":\"78649\",\"4\":\"0.5427896\"},{\"1\":\"Western Australia\",\"2\":\"Tangney\",\"3\":\"78602\",\"4\":\"0.6163360\"},{\"1\":\"New South Wales\",\"2\":\"Blaxland\",\"3\":\"78552\",\"4\":\"0.2605066\"},{\"1\":\"Victoria\",\"2\":\"Aston\",\"3\":\"78419\",\"4\":\"0.6197480\"},{\"1\":\"Queensland\",\"2\":\"Moreton\",\"3\":\"78051\",\"4\":\"0.6092431\"},{\"1\":\"Western Australia\",\"2\":\"O'Connor\",\"3\":\"77775\",\"4\":\"0.5616899\"},{\"1\":\"Queensland\",\"2\":\"Forde\",\"3\":\"77753\",\"4\":\"0.6054668\"},{\"1\":\"Western Australia\",\"2\":\"Brand\",\"3\":\"77628\",\"4\":\"0.6709327\"},{\"1\":\"Western Australia\",\"2\":\"Burt\",\"3\":\"77502\",\"4\":\"0.5697180\"},{\"1\":\"Western Australia\",\"2\":\"Stirling\",\"3\":\"77475\",\"4\":\"0.6110500\"},{\"1\":\"Queensland\",\"2\":\"Dawson\",\"3\":\"77343\",\"4\":\"0.5514662\"},{\"1\":\"Western Australia\",\"2\":\"Hasluck\",\"3\":\"76946\",\"4\":\"0.6241201\"},{\"1\":\"New South Wales\",\"2\":\"Fowler\",\"3\":\"76857\",\"4\":\"0.3634003\"},{\"1\":\"South Australia\",\"2\":\"Grey\",\"3\":\"76821\",\"4\":\"0.5330521\"},{\"1\":\"Queensland\",\"2\":\"Herbert\",\"3\":\"76758\",\"4\":\"0.6284699\"},{\"1\":\"New South Wales\",\"2\":\"Parramatta\",\"3\":\"76534\",\"4\":\"0.3838113\"},{\"1\":\"Queensland\",\"2\":\"Rankin\",\"3\":\"76428\",\"4\":\"0.5456025\"},{\"1\":\"Western Australia\",\"2\":\"Swan\",\"3\":\"76108\",\"4\":\"0.6466157\"},{\"1\":\"Queensland\",\"2\":\"Flynn\",\"3\":\"76065\",\"4\":\"0.5147554\"},{\"1\":\"Western Australia\",\"2\":\"Cowan\",\"3\":\"75647\",\"4\":\"0.5882088\"},{\"1\":\"Queensland\",\"2\":\"Leichhardt\",\"3\":\"75595\",\"4\":\"0.6336589\"},{\"1\":\"Queensland\",\"2\":\"Oxley\",\"3\":\"74244\",\"4\":\"0.6032829\"},{\"1\":\"Victoria\",\"2\":\"Bruce\",\"3\":\"74104\",\"4\":\"0.4691321\"},{\"1\":\"Queensland\",\"2\":\"Capricornia\",\"3\":\"74064\",\"4\":\"0.5406317\"},{\"1\":\"Queensland\",\"2\":\"Kennedy\",\"3\":\"71207\",\"4\":\"0.4674109\"},{\"1\":\"Western Australia\",\"2\":\"Durack\",\"3\":\"66626\",\"4\":\"0.5916426\"},{\"1\":\"Tasmania\",\"2\":\"Franklin\",\"3\":\"65231\",\"4\":\"0.6876806\"},{\"1\":\"Tasmania\",\"2\":\"Lyons\",\"3\":\"61328\",\"4\":\"0.5869636\"},{\"1\":\"Tasmania\",\"2\":\"Denison\",\"3\":\"61164\",\"4\":\"0.7378232\"},{\"1\":\"Tasmania\",\"2\":\"Bass\",\"3\":\"58904\",\"4\":\"0.6169097\"},{\"1\":\"Tasmania\",\"2\":\"Braddon\",\"3\":\"55781\",\"4\":\"0.5402772\"},{\"1\":\"Northern Territory\",\"2\":\"Solomon\",\"3\":\"45575\",\"4\":\"0.6525565\"},{\"1\":\"Northern Territory\",\"2\":\"Lingiari(c)\",\"3\":\"35030\",\"4\":\"0.5447830\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nam_survey_ST_grouped %>% ggplot(aes(x=Married_Perc)) +\r\n  geom_histogram(color=\"black\",aes(fill=State_Territory),binwidth = 0.025) +\r\n  labs(title = \"Survey of Australians About Marriage Law Change\",\r\n       subtitle = \"Should the law be changed to allow same sex couples to marry?\",\r\n       x=\"Percent of Population Who Responded YES\",\r\n       y=\"Count of Divisions\")\r\n\r\n\r\n\r\n\r\nInteresting…No conclusions today and a lot of unanswered questions, but a good start to understanding the opinions of eligible Australian voters on the topic of the legality of same-sex marriage.\r\nSome notes before we leave.\r\nI would like to better understand and apply formatting within Rmarkdown/Distill documents. This page is not as clear as I would want it to be without additional adjustments.\r\nThere are a couple of cleaning/wrangling operations that I would like to learn to perform in a more efficient manner. For instance, assigning the State_Territory variable was entirely manual and not scalable.\r\n\r\n\r\n\r\n",
    "preview": "posts/httpsrpubscomtbartelloni862736/distill-preview.png",
    "last_modified": "2022-02-09T18:37:31-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomtcwilso3hw2dacss601/",
    "title": "Homework2_Wilson",
    "description": "HW2 - Reading in data and dplyr practice",
    "author": [
      {
        "name": "Thomas Wilson",
        "url": {}
      }
    ],
    "date": "2022-02-09",
    "categories": [],
    "contents": "\n\n\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nrailroad_2012_clean_county_tidy <- read_csv(\".//./railroad_2012_clean_county_tidy.csv\")\n\ndim(railroad_2012_clean_county_tidy)\n\n\n[1] 2930    3\n\n#Filter out counties with less than 100 employees and list from highest to lowest\nrailroad_2012_clean_county_tidy %>%\n  filter(total_employees > 100) %>%\n  arrange(desc(total_employees)) \n\n\n# A tibble: 530 x 3\n   state county           total_employees\n   <chr> <chr>                      <dbl>\n 1 IL    COOK                        8207\n 2 TX    TARRANT                     4235\n 3 NE    DOUGLAS                     3797\n 4 NY    SUFFOLK                     3685\n 5 VA    INDEPENDENT CITY            3249\n 6 FL    DUVAL                       3073\n 7 CA    SAN BERNARDINO              2888\n 8 CA    LOS ANGELES                 2545\n 9 TX    HARRIS                      2535\n10 NE    LINCOLN                     2289\n# … with 520 more rows\n\n```{.r .distill-force-highlighting-css}\n\n\n",
    "preview": {},
    "last_modified": "2022-02-09T18:36:58-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httprpubscomamerleaux861483/",
    "title": "HW1",
    "description": "third attempt :)",
    "author": [
      {
        "name": "April Merleaux",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:12-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httprpubscommeade68861931/",
    "title": "Distill Test 2",
    "description": "Distill test; take 2",
    "author": [
      {
        "name": "Justin Meade",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\nR Markdown\r\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\r\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\r\n\r\n\r\nsummary(cars)\r\n\r\n\r\n     speed           dist       \r\n Min.   : 4.0   Min.   :  2.00  \r\n 1st Qu.:12.0   1st Qu.: 26.00  \r\n Median :15.0   Median : 36.00  \r\n Mean   :15.4   Mean   : 42.98  \r\n 3rd Qu.:19.0   3rd Qu.: 56.00  \r\n Max.   :25.0   Max.   :120.00  \r\n\r\nIncluding Plots\r\nYou can also embed plots, for example:\r\n\r\n\r\n\r\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot.\r\n\r\n\r\n\r\n",
    "preview": "posts/httprpubscommeade68861931/distill-preview.png",
    "last_modified": "2022-02-03T21:54:06-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httprpubscomniharika861660/",
    "title": "HW1",
    "description": "This is an example of RMarkdown",
    "author": [
      {
        "name": "Niharika Pola",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\nThis is an example of calculating Speed from given data of distance and time and generating the speed Graph\r\n\r\n\r\ndistance<-c(24,78,564,55,600)\r\ntime<-c(3,12,90,10,100)\r\nspeed<-distance/time\r\nspeed\r\n\r\n\r\n[1] 8.000000 6.500000 6.266667 5.500000 6.000000\r\n\r\nbarplot(speed, main='Speed Graph in kms/hr',xlab='distance in kms',ylab='time in hours')\r\n\r\n\r\n\r\n\r\n##Thank You\r\n\r\n\r\n\r\n",
    "preview": "posts/httprpubscomniharika861660/distill-preview.png",
    "last_modified": "2022-02-03T21:54:02-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httprpubscomsnehalhw/",
    "title": "DACSS 601: HW1",
    "description": "Introduction to R",
    "author": [
      {
        "name": "Snehal Prabhu",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(readr)\r\ndata <- read_csv(file=\"C:/Users/sneha/Downloads/railroad_2012_clean_state.csv\")\r\nhead(data)\r\n\r\n\r\n# A tibble: 6 x 2\r\n  state total_employees\r\n  <chr>           <dbl>\r\n1 AE                  2\r\n2 AK                103\r\n3 AL               4257\r\n4 AP                  1\r\n5 AR               3871\r\n6 AZ               3153\r\n\r\n\r\n\r\ncolnames(data)\r\n\r\n\r\n[1] \"state\"           \"total_employees\"\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:05-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httprpubscomsnoutsnake860945/",
    "title": "Sasi Tansaraviput HW1",
    "description": "Test for RPubs DACSS601",
    "author": [
      {
        "name": "Sasi Tansaraviput",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:34-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsdamionperrygithubiodcss601postswelcome/",
    "title": "Homework 1",
    "description": "Pilot post for developing a blog through R via distill for DCSS601",
    "author": [
      {
        "name": "Damion Perry",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\nHW1\nHere is some text.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:22-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomethancampbell860941/",
    "title": "EthanCampbellHW1",
    "description": "First Assignment for DACSS.",
    "author": [
      {
        "name": "Ethan Campbell",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\nBasic Visualization\r\nHere we visulize the data set MPG and look into tank size and mpg on the hwy.\r\n\r\n\r\nggplot(data = mpg) +\r\n  geom_point(mapping = aes(x = displ, y = hwy))\r\n\r\n\r\n\r\n\r\nHere we start using a second aes function. (Size and Color)\r\n\r\n\r\nggplot(data = mpg) +\r\n  geom_point(mapping = aes(x = displ, y = hwy, size = cty, color = hwy))\r\n\r\n\r\n\r\n\r\nAdding and removing the legend. Change show.legend to False to turn it off.\r\n\r\n\r\nggplot(data = mpg) +\r\n  geom_smooth(mapping = aes(x = displ, y = hwy, color = drv),\r\n    show.legend = TRUE)\r\n\r\n\r\n\r\n\r\nHere is the combination of the above sets.\r\n\r\n\r\nggplot(data = mpg) + \r\n  geom_point(mapping = aes(x = displ, y = hwy, color = drv)) +\r\n  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv, color = drv),\r\n              show.legend = TRUE\r\n              )\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/httpsrpubscomethancampbell860941/distill-preview.png",
    "last_modified": "2022-02-03T21:53:25-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomhenryfnp860386/",
    "title": "Henry Nguyen, HW1",
    "description": "rpubs test for HW1",
    "author": [
      {
        "name": "Henry Nguyen",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:52-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomhmuleyumass861476/",
    "title": "Mulveyhw1",
    "description": "try #2",
    "author": [
      {
        "name": "Henry Mulvey",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\nR Markdown\r\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\r\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\r\n\r\n\r\nsummary(cars)\r\n\r\n\r\n     speed           dist       \r\n Min.   : 4.0   Min.   :  2.00  \r\n 1st Qu.:12.0   1st Qu.: 26.00  \r\n Median :15.0   Median : 36.00  \r\n Mean   :15.4   Mean   : 42.98  \r\n 3rd Qu.:19.0   3rd Qu.: 56.00  \r\n Max.   :25.0   Max.   :120.00  \r\n\r\nIncluding Plots\r\nYou can also embed plots, for example:\r\n\r\n\r\n\r\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot.\r\n\r\n\r\n\r\n",
    "preview": "posts/httpsrpubscomhmuleyumass861476/distill-preview.png",
    "last_modified": "2022-02-03T21:53:09-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomjnfarrell211861485/",
    "title": "HW1",
    "description": "HW 1 Resubmission",
    "author": [
      {
        "name": "Joseph Farrell",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:15-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscommanikanta860644/",
    "title": "HW1",
    "description": "Learning R",
    "author": [
      {
        "name": "Mani kanta Gogula",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:37-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomnorthonum859557/",
    "title": "HW1-ThirdTry",
    "description": "HW1-ThirdTry",
    "author": [
      {
        "name": "Jason OConnell",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:46-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomrahulg861591/",
    "title": "HW1",
    "description": "Retry",
    "author": [
      {
        "name": "Rahul Gundeti",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:44-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomrahulghw1retry/",
    "title": "HW1",
    "description": "Retry",
    "author": [
      {
        "name": "Rahul Gundeti",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:40-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomsshelke861618/",
    "title": "HW1 Shruti Shelke",
    "description": "This is DACSS601 HW1",
    "author": [
      {
        "name": "Shruti Shelke",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:55-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomtbartelloni860564/",
    "title": "Tory Bartelloni HW1 - Test Distill Article",
    "description": "How to complete the first homework assignment of the course.",
    "author": [
      {
        "name": "Tory Bartelloni",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\nPublish and post.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:58-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomtcwilso3860290/",
    "title": "HW1",
    "description": "HW1 - Practice with RPubs",
    "author": [
      {
        "name": "Thomas Wilson",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\n#RPubs practice\nAdd a new chunk by clicking the Insert Chunk button on the toolbar or by pressing Cmd+Option+I.\nWhen you save the notebook, an HTML file containing the code and output will be saved alongside it (click the Preview button or press Cmd+Shift+K to preview the HTML file).\nThe preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike Knit, Preview does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-03T21:52:59-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsshayehalleegithubiocoursework2022-01-30-dacss-601-hw01/",
    "title": "Shaye Hallee - DACSS 601 HW01",
    "description": "Post for HW01 for DACSS 601.",
    "author": [
      {
        "name": "Shaye Hallee",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:53:31-05:00",
    "input_file": {}
  },
  {
    "path": "posts/hw1/",
    "title": "HW1",
    "description": "DACSS 603",
    "author": [
      {
        "name": "Katie Popiela",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:57:17-05:00",
    "input_file": {}
  },
  {
    "path": "posts/sasi-tansaraviput-hw1/",
    "title": "Sasi Tansaraviput HW1",
    "description": "Test for RPubs DACSS601",
    "author": [
      {
        "name": "Sasi Tansaraviput",
        "url": {}
      }
    ],
    "date": "2022-02-03",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-03T21:57:58-05:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to DACSS 601",
    "description": "Welcome to DACSS 601: Foundations of Data Science. We hope you enjoy \nour student projects.",
    "author": [
      {
        "name": "Meredith Rolfe",
        "url": "http://umass.edu/sbs/dacss"
      }
    ],
    "date": "2022-01-26",
    "categories": [
      "welcome"
    ],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-01-31T21:49:59-05:00",
    "input_file": {}
  }
]
